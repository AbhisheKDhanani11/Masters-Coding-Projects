{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b1e2eb-84a8-40d3-8636-9698f20abcd1",
   "metadata": {},
   "source": [
    "# MailCast: Email to audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8dc5ac-e312-4f51-91ff-94c75158b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import google\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "from email.mime.text import MIMEText\n",
    "import requests\n",
    "from google.cloud import texttospeech\n",
    "from dotenv import load_dotenv\n",
    "from Keys import Gemini_api, OpenAi_api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb22d1f-4ac4-46f9-8b7b-beae8f19c9fc",
   "metadata": {},
   "source": [
    "# Part 1: User Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93385fc6-cea5-45a8-9188-d37907210dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to authenticate Gmail\n",
    "\"\"\"\n",
    "This function is used to autheticate the user and get the corresponding token of user gmail.\n",
    "\"\"\"\n",
    "def authenticate_gmail():\n",
    "    SCOPES = ['https://www.googleapis.com/auth/gmail.readonly'] # gmail readonly \n",
    "    creds = None\n",
    "    # if token alreadly exist\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # if token expired or does not exist\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request()) # refresh the token\n",
    "        else:\n",
    "            # Get the new token with auth_cred file that was obtained from goolge cloud api service\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('Auth_creds.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return build('gmail', 'v1', credentials=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eca1a9-450c-468f-b0fc-2f954ab9aa63",
   "metadata": {},
   "source": [
    "# Part 2: Data Preproceing\n",
    "### loading and cleaning Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b7e920-eca0-411d-92c7-ea8334304687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from email.utils import parseaddr\n",
    "import base64\n",
    "import re \n",
    "\n",
    "def get_email_content(service, max_results=1):\n",
    "    # get the latest Emails\n",
    "    results = service.users().messages().list(userId='me', maxResults=max_results).execute()\n",
    "    messages = results.get('messages', [])\n",
    "    emails = []\n",
    "\n",
    "    # getting the message \n",
    "    for message in messages:\n",
    "        msg = service.users().messages().get(userId='me', id=message['id'], format='full').execute() # message \n",
    "        headers = msg['payload']['headers'] # header of the Email\n",
    "        subject = next(header['value'] for header in headers if header['name'] == 'Subject') # Subject of the email\n",
    "\n",
    "        # getting the sender information\n",
    "        full_sender = next(header['value'] for header in headers if header['name'] == 'From')\n",
    "        sender_name, sender_email = parseaddr(full_sender)\n",
    "        sender = sender_name if sender_name else sender_email\n",
    "\n",
    "        # Email body getting the pain text and the html tags \n",
    "        body = \"\"\n",
    "        if 'parts' in msg['payload']:\n",
    "            parts = msg['payload']['parts']\n",
    "            plain_text = []\n",
    "            html_text = []\n",
    "            for part in parts:\n",
    "                if part['mimeType'] == 'text/plain':\n",
    "                    text = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8', errors='ignore').strip()\n",
    "                    plain_text.append(text)\n",
    "                elif part['mimeType'] == 'text/html':\n",
    "                    html_data = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8', errors='ignore')\n",
    "                    soup = BeautifulSoup(html_data, 'html.parser')\n",
    "                    relevant_text = []\n",
    "                    for element in soup.find_all(['div', 'p', 'h1', 'h2', 'h3', 'li'], recursive=True):\n",
    "                        text = element.get_text(strip=True)\n",
    "                        if text and not any(footer in text for footer in ['Update your email preferences', 'Unsubscribe', 'Â©']):\n",
    "                            relevant_text.append(text)\n",
    "                    html_text.append('\\n'.join(relevant_text))\n",
    "            \n",
    "            body = '\\n'.join(plain_text) if plain_text else '\\n'.join(html_text)\n",
    "            if not body or \"You are reading a plain text version\" in body:\n",
    "                body = '\\n'.join(plain_text + html_text)\n",
    "        else:\n",
    "            body = base64.urlsafe_b64decode(msg['payload']['body']['data']).decode('utf-8', errors='ignore').strip()\n",
    "        \n",
    "        # Cleaning the body \n",
    "        if body:\n",
    "            # 1. Remove URLs\n",
    "            body = re.sub(r'https?://\\S+', '', body)\n",
    "            body = re.sub(r'\\[https?://\\S+\\]', '', body) # Handles markdown-style links\n",
    "\n",
    "            # 2. Remove any text within angle brackets (like unsubscribe links)\n",
    "            body = re.sub(r'<.*?>', '', body)\n",
    "\n",
    "            # 3. Collapse multiple newlines into two, for readability\n",
    "            body = re.sub(r'\\n{3,}', '\\n\\n', body).strip()\n",
    "\n",
    "        if body:\n",
    "            emails.append({'subject': subject, 'sender': sender, 'body': body})\n",
    "            \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5d14b-ef43-4c30-80fd-921c5e7277c3",
   "metadata": {},
   "source": [
    "# Part 3: Script generation\n",
    "\n",
    "###### This part will pass the email body to llm to get scipt to generate the audio file.\n",
    "###### It will generate the scipt in two part.\n",
    "###### First it will read the whole email.\n",
    "###### in second part it will generate a precise summary of the email and conbine both of them to generate the scipt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa058db4-83eb-4b3a-a883-e3fb85f626ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import google.generativeai as genai\n",
    "\n",
    "def generate_podcast_script(email_content, api_key=None):\n",
    "    if not api_key:\n",
    "        api_key = Gemini_api\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    clean_text = email_content['body']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a podcast host for \"Inbox Insights.\" Your task is to create a script from an email.\n",
    "    The sender is \"{email_content['sender']}\" and the subject is \"{email_content['subject']}\".\n",
    "\n",
    "    Your script MUST follow this exact two-part structure:\n",
    "\n",
    "    **Part 1: The Verbatim Reading**\n",
    "    1.  Start with a host introduction, mentioning the sender and subject.\n",
    "    2.  Use a transition phrase like, \"And now, here is the full text of the email.\"\n",
    "    3.  After the transition, you MUST reproduce the email content below **exactly as it is written**. Insert the text directly into the host's speech. Do NOT use stage directions like (Host reads email).\n",
    "\n",
    "    **Part 2: The Summary**\n",
    "    1.  After reproducing the full email text, use a transition phrase like, \"And that was the email. Now for a quick summary.\"\n",
    "    2.  Provide a concise summary of the email's key points.\n",
    "    3.  Conclude the episode.\n",
    "\n",
    "    **Formatting:** The entire output must be dialogue for the host, starting with \"**Host:**\".\n",
    "\n",
    "    --- EMAIL CONTENT TO REPRODUCE VERBATIM ---\n",
    "    {clean_text}\n",
    "    --- END OF EMAIL CONTENT ---\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "    # Adding safety settings to reduce the chance of the model refusing to process content\n",
    "    safety_settings = [\n",
    "        {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    ]\n",
    "    response = model.generate_content(prompt, safety_settings=safety_settings)\n",
    "\n",
    "    if not response.parts:\n",
    "        return \"**Host:** I'm sorry, but the content of this email could not be processed for the podcast. This may be due to safety filters or other processing issues.\"\n",
    "        \n",
    "    script = response.text.strip()\n",
    "    return script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b0730-7ede-4ee7-b27a-69b0fcb5f855",
   "metadata": {},
   "source": [
    "# Part 4: Main text to speech generation\n",
    "###### This part of the code is used to generate the audio file from the script generated by the llm.\n",
    "###### The model used to generate the audio is OpenAi TTS. it has a limi of only 4096 tokens.\n",
    "###### So if the email is longer then it wont generate the audio.\n",
    "###### To address this the input is divided in to max 4000 token chunks and each chunk is then used to generate the audio.\n",
    "###### and at the end combine all the chunk audio into a one single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a8fdf8-9034-43e9-aefd-ebd601ba915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pydub import AudioSegment \n",
    "import io \n",
    "\n",
    "def text_to_speech(script, output_file=\"output/podcast.mp3\", api_key=None):\n",
    "    if not api_key:\n",
    "        api_key = OpenAi_api\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Clean the script to get dialogue lines \n",
    "    dialogue_lines = []\n",
    "    for line in script.split('\\n'):\n",
    "        cleaned_line = re.sub(r'^\\*\\*\\w+:\\*\\*\\s*', '', line).strip()\n",
    "        if cleaned_line and not cleaned_line.startswith('('):\n",
    "            dialogue_lines.append(cleaned_line)\n",
    "    \n",
    "    full_text = '\\n'.join(dialogue_lines)\n",
    "\n",
    "    # Chunk the text into smaller pieces under the 4096 character limit\n",
    "    # We use 4000 as a safe buffer\n",
    "    char_limit = 4000\n",
    "    text_chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for line in full_text.split('\\n'):\n",
    "        # If adding the next line doesn't exceed the limit, add it\n",
    "        if len(current_chunk) + len(line) + 1 < char_limit:\n",
    "            current_chunk += line + '\\n'\n",
    "        # Otherwise, this chunk is finished. Store it and start a new one.\n",
    "        else:\n",
    "            text_chunks.append(current_chunk)\n",
    "            current_chunk = line + '\\n'\n",
    "    \n",
    "    text_chunks.append(current_chunk) # Add the final chunk\n",
    "\n",
    "    print(f\"Text has been split into {len(text_chunks)} chunks to handle API limits.\")\n",
    "\n",
    "    # Process each chunk and combine the audio\n",
    "    combined_audio = AudioSegment.empty()\n",
    "\n",
    "    for i, chunk in enumerate(text_chunks):\n",
    "        # Skip any chunks that might be empty\n",
    "        if not chunk.strip():\n",
    "            continue\n",
    "            \n",
    "        print(f\"Generating audio for chunk {i + 1}/{len(text_chunks)}...\")\n",
    "        try:\n",
    "            # Get the audio data for the current chunk\n",
    "            response = client.audio.speech.create(\n",
    "                model=\"tts-1\",\n",
    "                voice=\"nova\",\n",
    "                input=chunk,\n",
    "            )\n",
    "\n",
    "            # Load the audio data from the response into an in-memory file\n",
    "            audio_bytes = io.BytesIO(response.content)\n",
    "            \n",
    "            # Load this chunk's audio into a pydub AudioSegment\n",
    "            audio_segment = AudioSegment.from_mp3(audio_bytes)\n",
    "            \n",
    "            # Append (concatenate) this audio segment to the combined audio\n",
    "            combined_audio += audio_segment\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {i+1}: {e}\")\n",
    "            continue # Continue to the next chunk even if one fails\n",
    "            \n",
    "    # Export the final, combined audio file\n",
    "    try:\n",
    "        print(\"Exporting combined audio file...\")\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        combined_audio.export(output_file, format=\"mp3\")\n",
    "        print(\"Audio generation completed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting audio file: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "    # Verify the output file\n",
    "    if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "        print(f\"Audio file created successfully at {output_file}.\")\n",
    "    else:\n",
    "        raise ValueError(\"Audio file is empty or not created. Check API key, model access, or input text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd72cf9-5ec5-4bb2-b519-1a5dda4327ba",
   "metadata": {},
   "source": [
    "# Main Pipeline\n",
    "###### This is the main part of the program that will use every function i have defined.\n",
    "###### To get clean email and generate the script and finally use that script to generate the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64ccaf0-4b33-458a-b75a-85a0c7437eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=110272889934-0uej1eu4cjdt94c1oog5qvqqncsou8dv.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A55402%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=UP8rYNMIJnfomKxB3bsVvSFHAvFZoS&access_type=offline\n",
      "Processing email: Fwd: Self-driving cars eye NY from Abhishek Dhanani\n",
      "**Host:** Welcome back to Inbox Insights, the podcast that dives deep into the most interesting emails from your inbox. Today we're looking at an email forwarded to our listener, Abhishek Dhanani.  The subject line is, \"Fwd: Self-driving cars eye NY.\"  And now, here is the full text of the email.\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Superhuman â€“ Zain Kahn \n",
      "Date: Sat, 21 Jun 2025, 1:07â€¯pm\n",
      "Subject: Self-driving cars eye NY\n",
      "To: cap.prince11@gmail.com \n",
      "\n",
      "\n",
      "June 21, 2025   |   Read Online\n",
      "<\n",
      "\n",
      "*Welcome back, Superhuman.* Researchers in Italy dropped the worldâ€™s first\n",
      "flying humanoid robot this week. And robotaxis are looking to gradually\n",
      "expand their footprint across the US, with Alphabet-owned Waymo now eying a\n",
      "move to the Big Apple.\n",
      "\n",
      "*P.S. *The Robotics Special is designed to help you stay on the cutting\n",
      "edge of the latest breakthroughs and products in the industry. Our regular\n",
      "AI and Tech updates will resume as usual on Monday.\n",
      "\n",
      "*WHATâ€™S NEXT*\n",
      "*The most important news and breakthroughs in robotics this week*\n",
      "<\n",
      "\n",
      "Click here to watch the worldâ€™s first flying humanoid robot lift off the\n",
      "ground. Source: Italian Institute of Technology\n",
      "\n",
      "*1. Waymoâ€™s self-driving cars might make their way to NYC: *The company has\n",
      "put in an application to test its driverless cars in New York City â€” one of\n",
      "the first autonomous vehicle (AV) companies to request approval\n",
      "<\n",
      "for testing in the notoriously chaotic streets of Manhattan. The robotaxi\n",
      "company would initially operate with trained specialists behind the wheel\n",
      "since state law doesn't allow fully autonomous drives yet. The move comes\n",
      "as Tesla prepares to kick off its limited robotaxi operations in Austin.\n",
      "\n",
      "*2. Hexagon taps Nvidia Robotics to deploy its humanoid robot: *The company\n",
      "has unveiled\n",
      "<\n",
      "AEON, a humanoid robot built with Nvidiaâ€™s simulation platform for\n",
      "manufacturing and logistics tasks. The industrial bot hopes to tackle\n",
      "critical labor shortages by performing reality capture â€” automatically\n",
      "scanning assets and environments to generate precise 3D models. Using\n",
      "Nvidiaâ€™s Omniverse platform, AEON mastered core locomotion skills in just\n",
      "2-3 weeks instead of the typical 5-6 months.\n",
      "\n",
      "*3. Researchers claim theyâ€™ve built the â€˜first flying humanoid robotâ€™\n",
      ": *Italian\n",
      "researchers have unveiled\n",
      "<\n",
      "the iRonCub3, a jet-powered humanoid robot that they claim successfully\n",
      "hovered to about 50cm off the ground during its first test flight. Not\n",
      "exactly breaking altitude records, but still a significant leap. Unlike\n",
      "traditional drones, the robot must balance an entire humanoid body with\n",
      "movable limbs while adapting to complex, ever-changing aerodynamics. See it\n",
      "in action here\n",
      "<\n",
      "\n",
      "\n",
      "*PRESENTED BY SLACK*\n",
      "*Youâ€™ve never seen Slack like this before*\n",
      "<\n",
      "<\n",
      "\n",
      "*96 minutes:*\n",
      "<\n",
      "Thatâ€™s how much the average business owner loses every day chasing context\n",
      "between apps.\n",
      "\n",
      "But new AI features in Slack\n",
      "<\n",
      "help you win that time back with easy, no-code automations:\n",
      "\n",
      "   -\n",
      "\n",
      "   Automate manual tasks with just a few clicks\n",
      "   -\n",
      "\n",
      "   Summarize threads and find context, instantly\n",
      "   -\n",
      "\n",
      "   Create time-saving workflows with simple commands\n",
      "\n",
      "In sum: Youâ€™ll *get more time back with AI and automations in Slack *â€”\n",
      "without adding headcount.\n",
      "\n",
      "*Register for the webinar*\n",
      "<\n",
      " and learn how SMBs like yours are automating and using AI in Slack\n",
      "\n",
      "*ROBOTS IN ACTION*\n",
      "*How robots are transforming the world around us*\n",
      "\n",
      "Dr. Kenneth Liao performs the first successful, fully robotic heart\n",
      "transplant in the US. Source: Baylor College of Medicine\n",
      "\n",
      "ðŸ«€ *Heart Hack:* Houston surgeons have performed\n",
      "<\n",
      "the first fully robotic heart transplant in the US without cracking open\n",
      "the patient's chest. Instead of the traditional method of breaking the\n",
      "breastbone, doctors made small incisions in the abdomen, using robotic\n",
      "tools to remove the diseased heart and implant a donor organ.\n",
      "\n",
      "ðŸ›¡ï¸ *Gas Guardian:* A single undetected gas leak can cost facilities over\n",
      "$57,000 per year and pose a major safety risk in petrochemical plants. Now,\n",
      "Swiss robotics company ANYbotics has equipped\n",
      "<\n",
      "its ANYmal robot with gas leak detection capabilities, enabling the\n",
      "quadruped to pinpoint invisible leaks that manual inspections often miss.\n",
      "\n",
      "ðŸªš *Blade Runner:* KUKA has unveiled\n",
      "<\n",
      "the Catonator, a remote-controlled robotic saw armed with 2,000mm blades\n",
      "that can slice through steel, concrete, and aerospace composites with 0.1mm\n",
      "precision. It could potentially automate precision cutting tasks while\n",
      "eliminating emissions and improving worker safety in heavy industry\n",
      "applications.\n",
      "\n",
      "*INDUSTRY SNAPSHOT*\n",
      "*Everything else you need to know this week*\n",
      "\n",
      "Source: Reuters\n",
      "\n",
      "Here are the biggest developments in the robotics space that you should\n",
      "know about:\n",
      "\n",
      "   -\n",
      "\n",
      "   *Tesla* has been asked\n",
      "   <\n",
      "   by Democratic lawmakers to put off its robotaxi launch until September,\n",
      "   when new regulations with stricter state oversight take effect.\n",
      "   -\n",
      "\n",
      "   *Anduril* is joining hands\n",
      "   <\n",
      "   with German giant Rheinmetall to build military drones for European markets\n",
      "   â€” a shift toward faster innovation in European defense.\n",
      "   -\n",
      "\n",
      "   *A recent Gallup poll* shows\n",
      "   <\n",
      "   that 15% of US workers believe that AI or robots may likely replace their\n",
      "   jobs.\n",
      "   -\n",
      "\n",
      "   *Amazon's* Zoox just opened\n",
      "   <\n",
      "   its first production facility in Hayward, California, where it eventually\n",
      "   expects to build over 10,000 electric AVs annually.\n",
      "   -\n",
      "\n",
      "   *EngineAI* has open-sourced\n",
      "   <\n",
      "   a dev suite designed to accelerate humanoid robot creation by removing\n",
      "   technical barriers for startups and researchers.\n",
      "   -\n",
      "\n",
      "   *US startup Skydweller Aero* has partnered up\n",
      "   <\n",
      "   with French defense company Thales to deploy a solar-powered drone that can\n",
      "   stay in flight for a whole month.\n",
      "   -\n",
      "\n",
      "   *PrismaX* has launched with $11M to solve\n",
      "   <\n",
      "   one of the biggest bottlenecks in robotics â€” a lack of high-quality\n",
      "   training data for AI models.\n",
      "\n",
      "\n",
      "*ROBOT OF THE WEEK*\n",
      "*A robot that caught our eye this week*\n",
      "\n",
      "Source: Beatbot\n",
      "\n",
      "*Beatbotâ€™s AquaSense 2 is making waves as a Roomba for your swimming pool. *\n",
      "\n",
      "The robotic pool cleaner uses HybridSense AI mapping, 27 sensors, and 11\n",
      "motors to clean floors, walls, waterlines, and the water surface\n",
      "automatically while also offering water clarification. It can take on pools\n",
      "up to 3,875 square feet and runs for up to 10 hours on a single charge for\n",
      "surface cleaning.\n",
      "\n",
      "You can check it out here\n",
      "<\n",
      "\n",
      "\n",
      "*ROBO REEL*\n",
      "*Watch: Inventor builds real-life Transformer that shape-shifts into a ride*\n",
      "<\n",
      "\n",
      "Bruton's robot is a feat of practical engineering, designed with eagle-eyed\n",
      "detail. Source: James Bruton / YouTube\n",
      "\n",
      "*It was only a matter of time. *\n",
      "\n",
      "In what was every 90s kidâ€™s childhood dream, British inventor James Bruton\n",
      "has built\n",
      "<\n",
      "a rideable Transformer robot that actually shape-shifts from humanoid to\n",
      "vehicle. Unlike other transformer projects that leave no room for\n",
      "passengers, Bruton's creation can carry a human rider at functional speeds.\n",
      "\n",
      "Your opinion matters!\n",
      "\n",
      "Youâ€™re the reason our team spends hundreds of hours every week researching\n",
      "and writing this email. Please let us know what you thought of todayâ€™s\n",
      "email to help us create better emails for you.\n",
      "\n",
      "What did you think of today's email?\n",
      "\n",
      "Your feedback helps me create better emails for you!\n",
      "\n",
      "   - Loved it ðŸ§ ðŸ§ ðŸ§ \n",
      "   <\n",
      "   - It was ok ðŸ§ ðŸ§ \n",
      "   <\n",
      "   - Terrible ðŸ§ \n",
      "   <\n",
      "\n",
      "Until next time,\n",
      "\n",
      "Zain and the Superhuman AI team\n",
      "[image: tw]\n",
      "<\n",
      "[image:\n",
      "ig]\n",
      "<\n",
      "[image:\n",
      "yt]\n",
      "<\n",
      "[image:\n",
      "in]\n",
      "<\n",
      "\n",
      "\n",
      "Update your email preferences\n",
      "<\n",
      "or unsubscribe here\n",
      "<\n",
      "\n",
      "Â© 2025 Superhuman Newsletter\n",
      "\n",
      "228 Park Ave S, #29976, New York, New York 10003, United States\n",
      "<\n",
      "Terms of Service\n",
      "<\n",
      "\n",
      "And that was the email. Now for a quick summary.  This newsletter covers the latest in robotics, highlighting Waymo's application to test self-driving cars in New York City, the development of a new humanoid robot by Hexagon and Nvidia, and the unveiling of a flying humanoid robot in Italy.  It also includes various other advancements in the robotics field, from robotic heart transplants to automated pool cleaners.  A fascinating glimpse into a rapidly changing technological landscape. That's all for today's episode of Inbox Insights.  Join us next time for another fascinating email deep dive!\n",
      "Text has been split into 2 chunks to handle API limits.\n",
      "Generating audio for chunk 1/2...\n",
      "Generating audio for chunk 2/2...\n",
      "Exporting combined audio file...\n",
      "Audio generation completed.\n",
      "Audio file created successfully at output/podcast.mp3.\n",
      "\n",
      "Podcast audio saved to output/podcast.mp3\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    service = authenticate_gmail()\n",
    "    emails = get_email_content(service, max_results=1)\n",
    "    email = emails[0]\n",
    "    print(f\"Processing email: {email['subject']} from {email['sender']}\")\n",
    "    \n",
    "    script = generate_podcast_script(email)\n",
    "    print(script)\n",
    "    \n",
    "    output_file = \"output/podcast.mp3\"\n",
    "    try:\n",
    "        text_to_speech(script, output_file)\n",
    "        print(f\"\\nPodcast audio saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text_to_speech: {e}\")\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"File size: {os.path.getsize(output_file)} bytes\")\n",
    "        else:\n",
    "            print(\"Output file not created.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
