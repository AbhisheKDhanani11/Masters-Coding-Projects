{
  "best_metric": 0.999,
  "best_model_checkpoint": "./results\\checkpoint-625",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 625,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 2.2220399379730225,
      "learning_rate": 1.968e-05,
      "loss": 0.6842,
      "step": 10
    },
    {
      "epoch": 0.032,
      "grad_norm": 3.183824300765991,
      "learning_rate": 1.936e-05,
      "loss": 0.6138,
      "step": 20
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.7071149349212646,
      "learning_rate": 1.904e-05,
      "loss": 0.4866,
      "step": 30
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.2744224071502686,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.3076,
      "step": 40
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9571468234062195,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.1521,
      "step": 50
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.7650063037872314,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.0413,
      "step": 60
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.2176617532968521,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.0198,
      "step": 70
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1290934681892395,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.0107,
      "step": 80
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.0935480073094368,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.0085,
      "step": 90
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.07238160818815231,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0751,
      "step": 100
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.09632831066846848,
      "learning_rate": 1.648e-05,
      "loss": 0.0056,
      "step": 110
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.07344534993171692,
      "learning_rate": 1.6192e-05,
      "loss": 0.0153,
      "step": 120
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.05487934499979019,
      "learning_rate": 1.5872e-05,
      "loss": 0.0039,
      "step": 130
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.05741056427359581,
      "learning_rate": 1.5552e-05,
      "loss": 0.005,
      "step": 140
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.05030732601881027,
      "learning_rate": 1.5232000000000003e-05,
      "loss": 0.0031,
      "step": 150
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.15707886219024658,
      "learning_rate": 1.4912000000000002e-05,
      "loss": 0.0034,
      "step": 160
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.037157267332077026,
      "learning_rate": 1.4592000000000002e-05,
      "loss": 0.0029,
      "step": 170
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.03476692736148834,
      "learning_rate": 1.4272000000000002e-05,
      "loss": 0.0025,
      "step": 180
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.04146464169025421,
      "learning_rate": 1.3952000000000001e-05,
      "loss": 0.0024,
      "step": 190
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.030365511775016785,
      "learning_rate": 1.3632000000000001e-05,
      "loss": 0.0812,
      "step": 200
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.0815650001168251,
      "learning_rate": 1.3312e-05,
      "loss": 0.0023,
      "step": 210
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.04193864390254021,
      "learning_rate": 1.2992e-05,
      "loss": 0.0021,
      "step": 220
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.030000194907188416,
      "learning_rate": 1.2672000000000002e-05,
      "loss": 0.0018,
      "step": 230
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.026542888954281807,
      "learning_rate": 1.2352000000000001e-05,
      "loss": 0.0021,
      "step": 240
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.021565986797213554,
      "learning_rate": 1.2032000000000001e-05,
      "loss": 0.0253,
      "step": 250
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.0303744375705719,
      "learning_rate": 1.1712e-05,
      "loss": 0.0015,
      "step": 260
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.020617570728063583,
      "learning_rate": 1.1392e-05,
      "loss": 0.0033,
      "step": 270
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.022608766332268715,
      "learning_rate": 1.1072e-05,
      "loss": 0.0015,
      "step": 280
    },
    {
      "epoch": 0.464,
      "grad_norm": Infinity,
      "learning_rate": 1.0784e-05,
      "loss": 0.1291,
      "step": 290
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.02306065708398819,
      "learning_rate": 1.0464e-05,
      "loss": 0.0015,
      "step": 300
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.02159004658460617,
      "learning_rate": 1.0144e-05,
      "loss": 0.0018,
      "step": 310
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.018354037776589394,
      "learning_rate": 9.824000000000001e-06,
      "loss": 0.0014,
      "step": 320
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.02495620772242546,
      "learning_rate": 9.504e-06,
      "loss": 0.0013,
      "step": 330
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.027684587985277176,
      "learning_rate": 9.184e-06,
      "loss": 0.0013,
      "step": 340
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.020292609930038452,
      "learning_rate": 8.864e-06,
      "loss": 0.0012,
      "step": 350
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.019223788753151894,
      "learning_rate": 8.544000000000002e-06,
      "loss": 0.0012,
      "step": 360
    },
    {
      "epoch": 0.592,
      "grad_norm": 27.125080108642578,
      "learning_rate": 8.224000000000001e-06,
      "loss": 0.0602,
      "step": 370
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.017471108585596085,
      "learning_rate": 7.904000000000001e-06,
      "loss": 0.0011,
      "step": 380
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.01633991114795208,
      "learning_rate": 7.5840000000000006e-06,
      "loss": 0.001,
      "step": 390
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.02476722188293934,
      "learning_rate": 7.264000000000001e-06,
      "loss": 0.0011,
      "step": 400
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.04203813523054123,
      "learning_rate": 6.944000000000001e-06,
      "loss": 0.001,
      "step": 410
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.018367335200309753,
      "learning_rate": 6.6240000000000004e-06,
      "loss": 0.0011,
      "step": 420
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.015461398288607597,
      "learning_rate": 6.304e-06,
      "loss": 0.0049,
      "step": 430
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.014992307871580124,
      "learning_rate": 5.984000000000001e-06,
      "loss": 0.0009,
      "step": 440
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.015713144093751907,
      "learning_rate": 5.664e-06,
      "loss": 0.0011,
      "step": 450
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.05005753040313721,
      "learning_rate": 5.344e-06,
      "loss": 0.0009,
      "step": 460
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.012906648218631744,
      "learning_rate": 5.024e-06,
      "loss": 0.0072,
      "step": 470
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.018677346408367157,
      "learning_rate": 4.704e-06,
      "loss": 0.0008,
      "step": 480
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.036103926599025726,
      "learning_rate": 4.384000000000001e-06,
      "loss": 0.0819,
      "step": 490
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.015740765258669853,
      "learning_rate": 4.064e-06,
      "loss": 0.0008,
      "step": 500
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.014362195506691933,
      "learning_rate": 3.7440000000000005e-06,
      "loss": 0.0008,
      "step": 510
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.018555477261543274,
      "learning_rate": 3.424e-06,
      "loss": 0.0008,
      "step": 520
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.013797687366604805,
      "learning_rate": 3.1040000000000003e-06,
      "loss": 0.0009,
      "step": 530
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.019165312871336937,
      "learning_rate": 2.784e-06,
      "loss": 0.0008,
      "step": 540
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.01683703437447548,
      "learning_rate": 2.4640000000000005e-06,
      "loss": 0.0009,
      "step": 550
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.012600081041455269,
      "learning_rate": 2.144e-06,
      "loss": 0.0008,
      "step": 560
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.013640343211591244,
      "learning_rate": 1.8240000000000002e-06,
      "loss": 0.0008,
      "step": 570
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.013002287596464157,
      "learning_rate": 1.5040000000000001e-06,
      "loss": 0.0008,
      "step": 580
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.019937513396143913,
      "learning_rate": 1.1840000000000002e-06,
      "loss": 0.0008,
      "step": 590
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.012711812742054462,
      "learning_rate": 8.640000000000001e-07,
      "loss": 0.0008,
      "step": 600
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.014826992526650429,
      "learning_rate": 5.44e-07,
      "loss": 0.0008,
      "step": 610
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.011363361030817032,
      "learning_rate": 2.2400000000000002e-07,
      "loss": 0.0007,
      "step": 620
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.999,
      "eval_loss": 0.006002722308039665,
      "eval_runtime": 18.9251,
      "eval_samples_per_second": 52.84,
      "eval_steps_per_second": 6.605,
      "step": 625
    }
  ],
  "logging_steps": 10,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 165584248320000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
