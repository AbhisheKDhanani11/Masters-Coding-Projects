{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5130c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow fairlearn\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14993bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc6c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "response = requests.get(url)\n",
    "df = pd.read_csv(io.StringIO(response.text), names=column_names, na_values=\" ?\", skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0fa4062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "White                 0.854274\n",
       "Black                 0.095943\n",
       "Asian-Pac-Islander    0.031909\n",
       "Amer-Indian-Eskimo    0.009551\n",
       "Other                 0.008323\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5a76cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "Male      0.669205\n",
       "Female    0.330795\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d62a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= df.dropna() \n",
    "X = data.drop(\"income\", axis=1)\n",
    "y = (data[\"income\"] == \">50K\").astype(int) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285563b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b9cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features = X[[\"sex\", \"race\"]]  # Sex: 0=Female, 1=Male; Race: multiple categories\n",
    "X = X.drop([\"sex\", \"race\"], axis=1)  # Remove sensitive features from main feature set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ee693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 19:27:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/03/13 19:27:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model - Accuracy: 0.825\n",
      "Sex Fairness Diff: 0.088, Race Fairness Diff: 0.147\n",
      "Fair Model - Accuracy: 0.806\n",
      "Sex Fairness Diff: 0.100, Race Fairness Diff: 0.183\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 19:27:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/03/13 19:28:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model - Accuracy: 0.823\n",
      "Sex Fairness Diff: 0.118, Race Fairness Diff: 0.125\n",
      "Fair Model - Accuracy: 0.804\n",
      "Sex Fairness Diff: 0.121, Race Fairness Diff: 0.184\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 19:28:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/03/13 19:28:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model - Accuracy: 0.821\n",
      "Sex Fairness Diff: 0.119, Race Fairness Diff: 0.150\n",
      "Fair Model - Accuracy: 0.806\n",
      "Sex Fairness Diff: 0.126, Race Fairness Diff: 0.170\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 19:28:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/03/13 19:28:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model - Accuracy: 0.816\n",
      "Sex Fairness Diff: 0.107, Race Fairness Diff: 0.136\n",
      "Fair Model - Accuracy: 0.798\n",
      "Sex Fairness Diff: 0.112, Race Fairness Diff: 0.158\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 19:28:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/03/13 19:28:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model - Accuracy: 0.828\n",
      "Sex Fairness Diff: 0.099, Race Fairness Diff: 0.108\n",
      "Fair Model - Accuracy: 0.807\n",
      "Sex Fairness Diff: 0.117, Race Fairness Diff: 0.111\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# MLflow experiment setup\n",
    "mlflow.set_experiment(\"Adult_Income_Fairness_Classification\")\n",
    "\n",
    "def train_and_evaluate():\n",
    "    fold = 0\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        fold += 1\n",
    "        print(f\"\\nFold {fold}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        sensitive_train = sensitive_features.iloc[train_idx]\n",
    "        sensitive_test = sensitive_features.iloc[test_idx]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "\n",
    "        with mlflow.start_run(run_name=f\"fold_{fold}\"):\n",
    "    \n",
    "            base_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "            base_model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "         \n",
    "            fair_constraint = DemographicParity()\n",
    "            fair_model = ExponentiatedGradient(\n",
    "                LogisticRegression(random_state=42, max_iter=1000),\n",
    "                constraints=fair_constraint\n",
    "            )\n",
    "            fair_model.fit(X_train_scaled, y_train, sensitive_features=sensitive_train[\"sex\"])\n",
    "            \n",
    "      \n",
    "            base_pred = base_model.predict(X_test_scaled)\n",
    "            fair_pred = fair_model.predict(X_test_scaled)\n",
    "            \n",
    "            base_accuracy = accuracy_score(y_test, base_pred)\n",
    "            base_precision = precision_score(y_test, base_pred)\n",
    "            base_recall = recall_score(y_test, base_pred)\n",
    "            \n",
    "            fair_accuracy = accuracy_score(y_test, fair_pred)\n",
    "            fair_precision = precision_score(y_test, fair_pred)\n",
    "            fair_recall = recall_score(y_test, fair_pred)\n",
    "            \n",
    "   \n",
    "            mf_base_sex = MetricFrame(\n",
    "                metrics={\"accuracy\": accuracy_score},\n",
    "                y_true=y_test,\n",
    "                y_pred=base_pred,\n",
    "                sensitive_features=sensitive_test[\"sex\"]\n",
    "            )\n",
    "            mf_fair_sex = MetricFrame(\n",
    "                metrics={\"accuracy\": accuracy_score},\n",
    "                y_true=y_test,\n",
    "                y_pred=fair_pred,\n",
    "                sensitive_features=sensitive_test[\"sex\"]\n",
    "            )\n",
    "            \n",
    "       \n",
    "            mf_base_race = MetricFrame(\n",
    "                metrics={\"accuracy\": accuracy_score},\n",
    "                y_true=y_test,\n",
    "                y_pred=base_pred,\n",
    "                sensitive_features=sensitive_test[\"race\"]\n",
    "            )\n",
    "            mf_fair_race = MetricFrame(\n",
    "                metrics={\"accuracy\": accuracy_score},\n",
    "                y_true=y_test,\n",
    "                y_pred=fair_pred,\n",
    "                sensitive_features=sensitive_test[\"race\"]\n",
    "            )\n",
    "            \n",
    "     \n",
    "            mlflow.log_param(\"fold\", fold)\n",
    "            mlflow.log_param(\"model_type\", \"logistic_regression\")\n",
    "            \n",
    "        \n",
    "            mlflow.log_metric(\"base_accuracy\", base_accuracy)\n",
    "            mlflow.log_metric(\"base_precision\", base_precision)\n",
    "            mlflow.log_metric(\"base_recall\", base_recall)\n",
    "            \n",
    "\n",
    "            mlflow.log_metric(\"fair_accuracy\", fair_accuracy)\n",
    "            mlflow.log_metric(\"fair_precision\", fair_precision)\n",
    "            mlflow.log_metric(\"fair_recall\", fair_recall)\n",
    "            \n",
    "          \n",
    "            base_sex_diff = mf_base_sex.by_group[\"accuracy\"].max() - mf_base_sex.by_group[\"accuracy\"].min()\n",
    "            fair_sex_diff = mf_fair_sex.by_group[\"accuracy\"].max() - mf_fair_sex.by_group[\"accuracy\"].min()\n",
    "            base_race_diff = mf_base_race.by_group[\"accuracy\"].max() - mf_base_race.by_group[\"accuracy\"].min()\n",
    "            fair_race_diff = mf_fair_race.by_group[\"accuracy\"].max() - mf_fair_race.by_group[\"accuracy\"].min()\n",
    "            \n",
    "            mlflow.log_metric(\"base_sex_fairness_diff\", base_sex_diff)\n",
    "            mlflow.log_metric(\"fair_sex_fairness_diff\", fair_sex_diff)\n",
    "            mlflow.log_metric(\"base_race_fairness_diff\", base_race_diff)\n",
    "            mlflow.log_metric(\"fair_race_fairness_diff\", fair_race_diff)\n",
    "            \n",
    "   \n",
    "            mlflow.sklearn.log_model(base_model, \"base_model\")\n",
    "            mlflow.sklearn.log_model(fair_model, \"fair_model\")\n",
    "            \n",
    "            print(f\"Base Model - Accuracy: {base_accuracy:.3f}\")\n",
    "            print(f\"Sex Fairness Diff: {base_sex_diff:.3f}, Race Fairness Diff: {base_race_diff:.3f}\")\n",
    "            print(f\"Fair Model - Accuracy: {fair_accuracy:.3f}\")\n",
    "            print(f\"Sex Fairness Diff: {fair_sex_diff:.3f}, Race Fairness Diff: {fair_race_diff:.3f}\")\n",
    "\n",
    "train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
