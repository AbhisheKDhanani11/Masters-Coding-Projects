{
  "best_metric": 0.9991091314031181,
  "best_model_checkpoint": "./results\\checkpoint-3929",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3929,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0025451768897938407,
      "grad_norm": 2.1744871139526367,
      "learning_rate": 1.9949096462204125e-05,
      "loss": 0.6343,
      "step": 10
    },
    {
      "epoch": 0.0050903537795876815,
      "grad_norm": 2.4891276359558105,
      "learning_rate": 1.989819292440825e-05,
      "loss": 0.4462,
      "step": 20
    },
    {
      "epoch": 0.007635530669381522,
      "grad_norm": 1.029273271560669,
      "learning_rate": 1.9847289386612372e-05,
      "loss": 0.1752,
      "step": 30
    },
    {
      "epoch": 0.010180707559175363,
      "grad_norm": 3.179795026779175,
      "learning_rate": 1.9796385848816495e-05,
      "loss": 0.1002,
      "step": 40
    },
    {
      "epoch": 0.012725884448969204,
      "grad_norm": 0.2139580398797989,
      "learning_rate": 1.974548231102062e-05,
      "loss": 0.0277,
      "step": 50
    },
    {
      "epoch": 0.015271061338763044,
      "grad_norm": 0.1460544914007187,
      "learning_rate": 1.9694578773224742e-05,
      "loss": 0.0165,
      "step": 60
    },
    {
      "epoch": 0.017816238228556883,
      "grad_norm": 1.4738107919692993,
      "learning_rate": 1.9643675235428862e-05,
      "loss": 0.0108,
      "step": 70
    },
    {
      "epoch": 0.020361415118350726,
      "grad_norm": 0.09651731699705124,
      "learning_rate": 1.9592771697632985e-05,
      "loss": 0.007,
      "step": 80
    },
    {
      "epoch": 0.022906592008144565,
      "grad_norm": 0.07111304253339767,
      "learning_rate": 1.954186815983711e-05,
      "loss": 0.0058,
      "step": 90
    },
    {
      "epoch": 0.025451768897938407,
      "grad_norm": 0.06615225225687027,
      "learning_rate": 1.9490964622041232e-05,
      "loss": 0.0044,
      "step": 100
    },
    {
      "epoch": 0.027996945787732246,
      "grad_norm": 0.0615096241235733,
      "learning_rate": 1.9440061084245355e-05,
      "loss": 0.0045,
      "step": 110
    },
    {
      "epoch": 0.03054212267752609,
      "grad_norm": 0.04606650024652481,
      "learning_rate": 1.938915754644948e-05,
      "loss": 0.0033,
      "step": 120
    },
    {
      "epoch": 0.03308729956731993,
      "grad_norm": 0.04653395712375641,
      "learning_rate": 1.9338254008653602e-05,
      "loss": 0.0027,
      "step": 130
    },
    {
      "epoch": 0.03563247645711377,
      "grad_norm": 0.03322218731045723,
      "learning_rate": 1.9287350470857725e-05,
      "loss": 0.0041,
      "step": 140
    },
    {
      "epoch": 0.03817765334690761,
      "grad_norm": 0.03472663834691048,
      "learning_rate": 1.9241537286841436e-05,
      "loss": 0.0386,
      "step": 150
    },
    {
      "epoch": 0.04072283023670145,
      "grad_norm": 0.03613663837313652,
      "learning_rate": 1.919063374904556e-05,
      "loss": 0.0081,
      "step": 160
    },
    {
      "epoch": 0.04326800712649529,
      "grad_norm": 0.03081197291612625,
      "learning_rate": 1.9139730211249683e-05,
      "loss": 0.0019,
      "step": 170
    },
    {
      "epoch": 0.04581318401628913,
      "grad_norm": 0.04040049761533737,
      "learning_rate": 1.9088826673453806e-05,
      "loss": 0.0018,
      "step": 180
    },
    {
      "epoch": 0.048358360906082976,
      "grad_norm": 0.02691052109003067,
      "learning_rate": 1.903792313565793e-05,
      "loss": 0.0017,
      "step": 190
    },
    {
      "epoch": 0.050903537795876815,
      "grad_norm": 0.023161372169852257,
      "learning_rate": 1.8987019597862053e-05,
      "loss": 0.0015,
      "step": 200
    },
    {
      "epoch": 0.053448714685670654,
      "grad_norm": 0.02355583757162094,
      "learning_rate": 1.8936116060066176e-05,
      "loss": 0.0014,
      "step": 210
    },
    {
      "epoch": 0.05599389157546449,
      "grad_norm": 0.02502276748418808,
      "learning_rate": 1.88852125222703e-05,
      "loss": 0.0782,
      "step": 220
    },
    {
      "epoch": 0.05853906846525834,
      "grad_norm": 7.088483810424805,
      "learning_rate": 1.8834308984474423e-05,
      "loss": 0.0707,
      "step": 230
    },
    {
      "epoch": 0.06108424535505218,
      "grad_norm": 0.12373075634241104,
      "learning_rate": 1.8783405446678546e-05,
      "loss": 0.0023,
      "step": 240
    },
    {
      "epoch": 0.06362942224484602,
      "grad_norm": 0.04246485233306885,
      "learning_rate": 1.873250190888267e-05,
      "loss": 0.0018,
      "step": 250
    },
    {
      "epoch": 0.06617459913463986,
      "grad_norm": 0.02157665602862835,
      "learning_rate": 1.868159837108679e-05,
      "loss": 0.0014,
      "step": 260
    },
    {
      "epoch": 0.0687197760244337,
      "grad_norm": 0.02308380976319313,
      "learning_rate": 1.8630694833290913e-05,
      "loss": 0.0012,
      "step": 270
    },
    {
      "epoch": 0.07126495291422753,
      "grad_norm": 0.01572774536907673,
      "learning_rate": 1.8579791295495036e-05,
      "loss": 0.0011,
      "step": 280
    },
    {
      "epoch": 0.07381012980402138,
      "grad_norm": 0.016901517286896706,
      "learning_rate": 1.852888775769916e-05,
      "loss": 0.001,
      "step": 290
    },
    {
      "epoch": 0.07635530669381523,
      "grad_norm": 0.014867261983454227,
      "learning_rate": 1.8477984219903283e-05,
      "loss": 0.001,
      "step": 300
    },
    {
      "epoch": 0.07890048358360906,
      "grad_norm": 0.018492989242076874,
      "learning_rate": 1.8427080682107406e-05,
      "loss": 0.0009,
      "step": 310
    },
    {
      "epoch": 0.0814456604734029,
      "grad_norm": 0.017463427037000656,
      "learning_rate": 1.837617714431153e-05,
      "loss": 0.0008,
      "step": 320
    },
    {
      "epoch": 0.08399083736319674,
      "grad_norm": 4.732455253601074,
      "learning_rate": 1.8325273606515653e-05,
      "loss": 0.0056,
      "step": 330
    },
    {
      "epoch": 0.08653601425299058,
      "grad_norm": 0.01371514331549406,
      "learning_rate": 1.8274370068719777e-05,
      "loss": 0.0007,
      "step": 340
    },
    {
      "epoch": 0.08908119114278443,
      "grad_norm": 0.012131338939070702,
      "learning_rate": 1.82234665309239e-05,
      "loss": 0.0008,
      "step": 350
    },
    {
      "epoch": 0.09162636803257826,
      "grad_norm": 0.01583697646856308,
      "learning_rate": 1.8172562993128023e-05,
      "loss": 0.0528,
      "step": 360
    },
    {
      "epoch": 0.0941715449223721,
      "grad_norm": 0.017802461981773376,
      "learning_rate": 1.8121659455332147e-05,
      "loss": 0.0037,
      "step": 370
    },
    {
      "epoch": 0.09671672181216595,
      "grad_norm": 0.013953725807368755,
      "learning_rate": 1.807075591753627e-05,
      "loss": 0.0007,
      "step": 380
    },
    {
      "epoch": 0.09926189870195978,
      "grad_norm": 0.038336463272571564,
      "learning_rate": 1.8019852379740393e-05,
      "loss": 0.0007,
      "step": 390
    },
    {
      "epoch": 0.10180707559175363,
      "grad_norm": 0.015318765304982662,
      "learning_rate": 1.7968948841944517e-05,
      "loss": 0.0006,
      "step": 400
    },
    {
      "epoch": 0.10435225248154746,
      "grad_norm": 0.00846792384982109,
      "learning_rate": 1.791804530414864e-05,
      "loss": 0.0007,
      "step": 410
    },
    {
      "epoch": 0.10689742937134131,
      "grad_norm": 0.008009455166757107,
      "learning_rate": 1.7867141766352763e-05,
      "loss": 0.0005,
      "step": 420
    },
    {
      "epoch": 0.10944260626113515,
      "grad_norm": 0.0069696931168437,
      "learning_rate": 1.7816238228556887e-05,
      "loss": 0.0005,
      "step": 430
    },
    {
      "epoch": 0.11198778315092899,
      "grad_norm": 0.0738707110285759,
      "learning_rate": 1.776533469076101e-05,
      "loss": 0.0005,
      "step": 440
    },
    {
      "epoch": 0.11453296004072283,
      "grad_norm": 0.00866505317389965,
      "learning_rate": 1.7714431152965134e-05,
      "loss": 0.0004,
      "step": 450
    },
    {
      "epoch": 0.11707813693051668,
      "grad_norm": 0.007170131430029869,
      "learning_rate": 1.7663527615169257e-05,
      "loss": 0.0004,
      "step": 460
    },
    {
      "epoch": 0.11962331382031051,
      "grad_norm": 0.007899119518697262,
      "learning_rate": 1.761262407737338e-05,
      "loss": 0.0004,
      "step": 470
    },
    {
      "epoch": 0.12216849071010435,
      "grad_norm": 0.01749054156243801,
      "learning_rate": 1.7561720539577504e-05,
      "loss": 0.0005,
      "step": 480
    },
    {
      "epoch": 0.12471366759989819,
      "grad_norm": 0.0089559992775321,
      "learning_rate": 1.7510817001781627e-05,
      "loss": 0.0004,
      "step": 490
    },
    {
      "epoch": 0.12725884448969205,
      "grad_norm": 0.775725781917572,
      "learning_rate": 1.745991346398575e-05,
      "loss": 0.0004,
      "step": 500
    },
    {
      "epoch": 0.12980402137948588,
      "grad_norm": 0.005577174946665764,
      "learning_rate": 1.7409009926189874e-05,
      "loss": 0.0004,
      "step": 510
    },
    {
      "epoch": 0.1323491982692797,
      "grad_norm": 0.007680526003241539,
      "learning_rate": 1.7358106388393994e-05,
      "loss": 0.0003,
      "step": 520
    },
    {
      "epoch": 0.13489437515907354,
      "grad_norm": 0.013505937531590462,
      "learning_rate": 1.7307202850598117e-05,
      "loss": 0.1035,
      "step": 530
    },
    {
      "epoch": 0.1374395520488674,
      "grad_norm": 0.017894431948661804,
      "learning_rate": 1.725629931280224e-05,
      "loss": 0.0004,
      "step": 540
    },
    {
      "epoch": 0.13998472893866123,
      "grad_norm": 0.010266918689012527,
      "learning_rate": 1.7205395775006364e-05,
      "loss": 0.0006,
      "step": 550
    },
    {
      "epoch": 0.14252990582845507,
      "grad_norm": 0.017172394320368767,
      "learning_rate": 1.7154492237210487e-05,
      "loss": 0.0004,
      "step": 560
    },
    {
      "epoch": 0.14507508271824893,
      "grad_norm": 0.008445356972515583,
      "learning_rate": 1.710358869941461e-05,
      "loss": 0.0004,
      "step": 570
    },
    {
      "epoch": 0.14762025960804276,
      "grad_norm": 0.007375459652394056,
      "learning_rate": 1.7052685161618734e-05,
      "loss": 0.0004,
      "step": 580
    },
    {
      "epoch": 0.1501654364978366,
      "grad_norm": 0.00762843806296587,
      "learning_rate": 1.7001781623822857e-05,
      "loss": 0.0004,
      "step": 590
    },
    {
      "epoch": 0.15271061338763045,
      "grad_norm": 0.00583405839279294,
      "learning_rate": 1.695087808602698e-05,
      "loss": 0.0004,
      "step": 600
    },
    {
      "epoch": 0.15525579027742428,
      "grad_norm": 0.006335852202028036,
      "learning_rate": 1.6899974548231104e-05,
      "loss": 0.0003,
      "step": 610
    },
    {
      "epoch": 0.15780096716721811,
      "grad_norm": 0.008305170573294163,
      "learning_rate": 1.6849071010435227e-05,
      "loss": 0.0003,
      "step": 620
    },
    {
      "epoch": 0.16034614405701197,
      "grad_norm": 0.006585695780813694,
      "learning_rate": 1.679816747263935e-05,
      "loss": 0.0003,
      "step": 630
    },
    {
      "epoch": 0.1628913209468058,
      "grad_norm": 0.004588693380355835,
      "learning_rate": 1.6747263934843474e-05,
      "loss": 0.0003,
      "step": 640
    },
    {
      "epoch": 0.16543649783659964,
      "grad_norm": 0.0049707237631082535,
      "learning_rate": 1.6696360397047594e-05,
      "loss": 0.0003,
      "step": 650
    },
    {
      "epoch": 0.16798167472639347,
      "grad_norm": 0.008205498568713665,
      "learning_rate": 1.6645456859251717e-05,
      "loss": 0.0003,
      "step": 660
    },
    {
      "epoch": 0.17052685161618733,
      "grad_norm": 0.005396636668592691,
      "learning_rate": 1.659455332145584e-05,
      "loss": 0.0003,
      "step": 670
    },
    {
      "epoch": 0.17307202850598116,
      "grad_norm": 0.004899341147392988,
      "learning_rate": 1.6543649783659964e-05,
      "loss": 0.0003,
      "step": 680
    },
    {
      "epoch": 0.175617205395775,
      "grad_norm": 0.006576834246516228,
      "learning_rate": 1.6492746245864088e-05,
      "loss": 0.0003,
      "step": 690
    },
    {
      "epoch": 0.17816238228556885,
      "grad_norm": 0.005620075389742851,
      "learning_rate": 1.644184270806821e-05,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 0.1807075591753627,
      "grad_norm": 0.004127738066017628,
      "learning_rate": 1.6390939170272334e-05,
      "loss": 0.0002,
      "step": 710
    },
    {
      "epoch": 0.18325273606515652,
      "grad_norm": 0.006561041809618473,
      "learning_rate": 1.6340035632476458e-05,
      "loss": 0.0003,
      "step": 720
    },
    {
      "epoch": 0.18579791295495038,
      "grad_norm": 0.006382578518241644,
      "learning_rate": 1.628913209468058e-05,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 0.1883430898447442,
      "grad_norm": 0.0037178548518568277,
      "learning_rate": 1.6238228556884704e-05,
      "loss": 0.0002,
      "step": 740
    },
    {
      "epoch": 0.19088826673453804,
      "grad_norm": 0.00446360744535923,
      "learning_rate": 1.6187325019088828e-05,
      "loss": 0.0002,
      "step": 750
    },
    {
      "epoch": 0.1934334436243319,
      "grad_norm": 0.003897380782291293,
      "learning_rate": 1.613642148129295e-05,
      "loss": 0.0002,
      "step": 760
    },
    {
      "epoch": 0.19597862051412573,
      "grad_norm": 0.0037156061735004187,
      "learning_rate": 1.6085517943497074e-05,
      "loss": 0.0002,
      "step": 770
    },
    {
      "epoch": 0.19852379740391957,
      "grad_norm": 0.0036543423775583506,
      "learning_rate": 1.6034614405701198e-05,
      "loss": 0.0002,
      "step": 780
    },
    {
      "epoch": 0.20106897429371343,
      "grad_norm": 0.002878059633076191,
      "learning_rate": 1.598371086790532e-05,
      "loss": 0.0002,
      "step": 790
    },
    {
      "epoch": 0.20361415118350726,
      "grad_norm": 0.005545167252421379,
      "learning_rate": 1.5932807330109445e-05,
      "loss": 0.0002,
      "step": 800
    },
    {
      "epoch": 0.2061593280733011,
      "grad_norm": 0.0036190219689160585,
      "learning_rate": 1.5881903792313568e-05,
      "loss": 0.0002,
      "step": 810
    },
    {
      "epoch": 0.20870450496309492,
      "grad_norm": 0.004983288701623678,
      "learning_rate": 1.583100025451769e-05,
      "loss": 0.0002,
      "step": 820
    },
    {
      "epoch": 0.21124968185288878,
      "grad_norm": 0.002840182511135936,
      "learning_rate": 1.5780096716721815e-05,
      "loss": 0.0002,
      "step": 830
    },
    {
      "epoch": 0.21379485874268261,
      "grad_norm": 0.003610342973843217,
      "learning_rate": 1.5729193178925938e-05,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 0.21634003563247645,
      "grad_norm": 0.003341625677421689,
      "learning_rate": 1.567828964113006e-05,
      "loss": 0.0002,
      "step": 850
    },
    {
      "epoch": 0.2188852125222703,
      "grad_norm": 0.002090559108182788,
      "learning_rate": 1.5627386103334185e-05,
      "loss": 0.0002,
      "step": 860
    },
    {
      "epoch": 0.22143038941206414,
      "grad_norm": 0.002944714156910777,
      "learning_rate": 1.5576482565538308e-05,
      "loss": 0.0002,
      "step": 870
    },
    {
      "epoch": 0.22397556630185797,
      "grad_norm": 0.004210468847304583,
      "learning_rate": 1.552557902774243e-05,
      "loss": 0.0002,
      "step": 880
    },
    {
      "epoch": 0.22652074319165183,
      "grad_norm": 0.00308751012198627,
      "learning_rate": 1.5474675489946555e-05,
      "loss": 0.0002,
      "step": 890
    },
    {
      "epoch": 0.22906592008144566,
      "grad_norm": 0.002937573939561844,
      "learning_rate": 1.5423771952150678e-05,
      "loss": 0.0002,
      "step": 900
    },
    {
      "epoch": 0.2316110969712395,
      "grad_norm": 0.002231996739283204,
      "learning_rate": 1.5372868414354798e-05,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 0.23415627386103335,
      "grad_norm": 0.0036014735233038664,
      "learning_rate": 1.532196487655892e-05,
      "loss": 0.0002,
      "step": 920
    },
    {
      "epoch": 0.23670145075082719,
      "grad_norm": 0.0040948581881821156,
      "learning_rate": 1.5271061338763045e-05,
      "loss": 0.0002,
      "step": 930
    },
    {
      "epoch": 0.23924662764062102,
      "grad_norm": 0.002991223242133856,
      "learning_rate": 1.5220157800967168e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 0.24179180453041485,
      "grad_norm": 0.002600274980068207,
      "learning_rate": 1.5169254263171292e-05,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 0.2443369814202087,
      "grad_norm": 0.0035705023910850286,
      "learning_rate": 1.5118350725375415e-05,
      "loss": 0.0001,
      "step": 960
    },
    {
      "epoch": 0.24688215831000254,
      "grad_norm": 0.0030738243367522955,
      "learning_rate": 1.5067447187579538e-05,
      "loss": 0.0001,
      "step": 970
    },
    {
      "epoch": 0.24942733519979637,
      "grad_norm": 0.0026129321195185184,
      "learning_rate": 1.5016543649783662e-05,
      "loss": 0.0001,
      "step": 980
    },
    {
      "epoch": 0.2519725120895902,
      "grad_norm": 0.0033439602702856064,
      "learning_rate": 1.4965640111987785e-05,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 0.2545176889793841,
      "grad_norm": 0.0024876254610717297,
      "learning_rate": 1.4914736574191908e-05,
      "loss": 0.0977,
      "step": 1000
    },
    {
      "epoch": 0.2570628658691779,
      "grad_norm": 0.007073931396007538,
      "learning_rate": 1.4863833036396032e-05,
      "loss": 0.0002,
      "step": 1010
    },
    {
      "epoch": 0.25960804275897176,
      "grad_norm": 0.009164588525891304,
      "learning_rate": 1.4812929498600155e-05,
      "loss": 0.0004,
      "step": 1020
    },
    {
      "epoch": 0.2621532196487656,
      "grad_norm": 0.00521527836099267,
      "learning_rate": 1.4762025960804279e-05,
      "loss": 0.0003,
      "step": 1030
    },
    {
      "epoch": 0.2646983965385594,
      "grad_norm": 0.004880232270807028,
      "learning_rate": 1.4711122423008399e-05,
      "loss": 0.0002,
      "step": 1040
    },
    {
      "epoch": 0.26724357342835325,
      "grad_norm": 0.5438674092292786,
      "learning_rate": 1.4660218885212522e-05,
      "loss": 0.0949,
      "step": 1050
    },
    {
      "epoch": 0.2697887503181471,
      "grad_norm": 0.011167856864631176,
      "learning_rate": 1.4609315347416645e-05,
      "loss": 0.0006,
      "step": 1060
    },
    {
      "epoch": 0.272333927207941,
      "grad_norm": 0.006482760421931744,
      "learning_rate": 1.4558411809620769e-05,
      "loss": 0.0003,
      "step": 1070
    },
    {
      "epoch": 0.2748791040977348,
      "grad_norm": 0.0024359954986721277,
      "learning_rate": 1.4507508271824892e-05,
      "loss": 0.0003,
      "step": 1080
    },
    {
      "epoch": 0.27742428098752864,
      "grad_norm": 0.005551972892135382,
      "learning_rate": 1.4456604734029015e-05,
      "loss": 0.0003,
      "step": 1090
    },
    {
      "epoch": 0.27996945787732247,
      "grad_norm": 0.005060707684606314,
      "learning_rate": 1.4405701196233139e-05,
      "loss": 0.0002,
      "step": 1100
    },
    {
      "epoch": 0.2825146347671163,
      "grad_norm": 0.0026059956289827824,
      "learning_rate": 1.4354797658437262e-05,
      "loss": 0.0002,
      "step": 1110
    },
    {
      "epoch": 0.28505981165691013,
      "grad_norm": 0.004421660210937262,
      "learning_rate": 1.4303894120641385e-05,
      "loss": 0.0002,
      "step": 1120
    },
    {
      "epoch": 0.287604988546704,
      "grad_norm": 0.0031428204383701086,
      "learning_rate": 1.4252990582845509e-05,
      "loss": 0.0002,
      "step": 1130
    },
    {
      "epoch": 0.29015016543649785,
      "grad_norm": 0.0026474366895854473,
      "learning_rate": 1.4202087045049632e-05,
      "loss": 0.0002,
      "step": 1140
    },
    {
      "epoch": 0.2926953423262917,
      "grad_norm": 0.007846513763070107,
      "learning_rate": 1.4151183507253756e-05,
      "loss": 0.0002,
      "step": 1150
    },
    {
      "epoch": 0.2952405192160855,
      "grad_norm": 0.004048534668982029,
      "learning_rate": 1.4100279969457879e-05,
      "loss": 0.0001,
      "step": 1160
    },
    {
      "epoch": 0.29778569610587935,
      "grad_norm": 0.00532602658495307,
      "learning_rate": 1.4049376431662e-05,
      "loss": 0.0002,
      "step": 1170
    },
    {
      "epoch": 0.3003308729956732,
      "grad_norm": 0.0033569755032658577,
      "learning_rate": 1.3998472893866124e-05,
      "loss": 0.0002,
      "step": 1180
    },
    {
      "epoch": 0.302876049885467,
      "grad_norm": 0.0035091987811028957,
      "learning_rate": 1.3947569356070247e-05,
      "loss": 0.0001,
      "step": 1190
    },
    {
      "epoch": 0.3054212267752609,
      "grad_norm": 0.0019062996143475175,
      "learning_rate": 1.389666581827437e-05,
      "loss": 0.0002,
      "step": 1200
    },
    {
      "epoch": 0.30796640366505473,
      "grad_norm": 0.003504429943859577,
      "learning_rate": 1.3845762280478494e-05,
      "loss": 0.0001,
      "step": 1210
    },
    {
      "epoch": 0.31051158055484857,
      "grad_norm": 0.0017647072672843933,
      "learning_rate": 1.3794858742682617e-05,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 0.3130567574446424,
      "grad_norm": 0.004072538577020168,
      "learning_rate": 1.374395520488674e-05,
      "loss": 0.0001,
      "step": 1230
    },
    {
      "epoch": 0.31560193433443623,
      "grad_norm": 0.002468009712174535,
      "learning_rate": 1.3693051667090864e-05,
      "loss": 0.0001,
      "step": 1240
    },
    {
      "epoch": 0.31814711122423006,
      "grad_norm": 0.001824016566388309,
      "learning_rate": 1.3642148129294987e-05,
      "loss": 0.0001,
      "step": 1250
    },
    {
      "epoch": 0.32069228811402395,
      "grad_norm": 0.002474147593602538,
      "learning_rate": 1.359124459149911e-05,
      "loss": 0.0001,
      "step": 1260
    },
    {
      "epoch": 0.3232374650038178,
      "grad_norm": 0.0015507215866819024,
      "learning_rate": 1.3540341053703234e-05,
      "loss": 0.0001,
      "step": 1270
    },
    {
      "epoch": 0.3257826418936116,
      "grad_norm": 0.002257280284538865,
      "learning_rate": 1.3489437515907358e-05,
      "loss": 0.0001,
      "step": 1280
    },
    {
      "epoch": 0.32832781878340545,
      "grad_norm": 0.0031483748462051153,
      "learning_rate": 1.343853397811148e-05,
      "loss": 0.0001,
      "step": 1290
    },
    {
      "epoch": 0.3308729956731993,
      "grad_norm": 0.005132053047418594,
      "learning_rate": 1.3387630440315603e-05,
      "loss": 0.0001,
      "step": 1300
    },
    {
      "epoch": 0.3334181725629931,
      "grad_norm": 0.002435731701552868,
      "learning_rate": 1.3336726902519726e-05,
      "loss": 0.0001,
      "step": 1310
    },
    {
      "epoch": 0.33596334945278694,
      "grad_norm": 0.0020827646367251873,
      "learning_rate": 1.328582336472385e-05,
      "loss": 0.0001,
      "step": 1320
    },
    {
      "epoch": 0.33850852634258083,
      "grad_norm": 0.002819554880261421,
      "learning_rate": 1.3234919826927973e-05,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 0.34105370323237466,
      "grad_norm": 0.0018189010443165898,
      "learning_rate": 1.3184016289132096e-05,
      "loss": 0.0001,
      "step": 1340
    },
    {
      "epoch": 0.3435988801221685,
      "grad_norm": 0.0024376949295401573,
      "learning_rate": 1.313311275133622e-05,
      "loss": 0.0001,
      "step": 1350
    },
    {
      "epoch": 0.3461440570119623,
      "grad_norm": 0.0021335678175091743,
      "learning_rate": 1.3082209213540343e-05,
      "loss": 0.0001,
      "step": 1360
    },
    {
      "epoch": 0.34868923390175616,
      "grad_norm": 0.002289124531671405,
      "learning_rate": 1.3031305675744466e-05,
      "loss": 0.0001,
      "step": 1370
    },
    {
      "epoch": 0.35123441079155,
      "grad_norm": 0.001672787475399673,
      "learning_rate": 1.298040213794859e-05,
      "loss": 0.0001,
      "step": 1380
    },
    {
      "epoch": 0.3537795876813439,
      "grad_norm": 0.001967706484720111,
      "learning_rate": 1.2929498600152713e-05,
      "loss": 0.0001,
      "step": 1390
    },
    {
      "epoch": 0.3563247645711377,
      "grad_norm": 0.003547277767211199,
      "learning_rate": 1.2878595062356836e-05,
      "loss": 0.0001,
      "step": 1400
    },
    {
      "epoch": 0.35886994146093154,
      "grad_norm": 0.001424613525159657,
      "learning_rate": 1.282769152456096e-05,
      "loss": 0.0001,
      "step": 1410
    },
    {
      "epoch": 0.3614151183507254,
      "grad_norm": 0.0013143062824383378,
      "learning_rate": 1.277678798676508e-05,
      "loss": 0.0001,
      "step": 1420
    },
    {
      "epoch": 0.3639602952405192,
      "grad_norm": 0.0016888586105778813,
      "learning_rate": 1.2725884448969203e-05,
      "loss": 0.0001,
      "step": 1430
    },
    {
      "epoch": 0.36650547213031304,
      "grad_norm": 0.0015642046928405762,
      "learning_rate": 1.2674980911173326e-05,
      "loss": 0.0001,
      "step": 1440
    },
    {
      "epoch": 0.3690506490201069,
      "grad_norm": 0.0016248495085164905,
      "learning_rate": 1.262407737337745e-05,
      "loss": 0.0001,
      "step": 1450
    },
    {
      "epoch": 0.37159582590990076,
      "grad_norm": 0.0017012663884088397,
      "learning_rate": 1.2573173835581573e-05,
      "loss": 0.0001,
      "step": 1460
    },
    {
      "epoch": 0.3741410027996946,
      "grad_norm": 0.001251394860446453,
      "learning_rate": 1.2522270297785696e-05,
      "loss": 0.0001,
      "step": 1470
    },
    {
      "epoch": 0.3766861796894884,
      "grad_norm": 0.0015436060493811965,
      "learning_rate": 1.247136675998982e-05,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 0.37923135657928225,
      "grad_norm": 0.0061066835187375546,
      "learning_rate": 1.2420463222193943e-05,
      "loss": 0.1133,
      "step": 1490
    },
    {
      "epoch": 0.3817765334690761,
      "grad_norm": 0.008973851799964905,
      "learning_rate": 1.2369559684398067e-05,
      "loss": 0.0002,
      "step": 1500
    },
    {
      "epoch": 0.3843217103588699,
      "grad_norm": 0.005707031115889549,
      "learning_rate": 1.231865614660219e-05,
      "loss": 0.0002,
      "step": 1510
    },
    {
      "epoch": 0.3868668872486638,
      "grad_norm": 0.004366611130535603,
      "learning_rate": 1.2267752608806313e-05,
      "loss": 0.0002,
      "step": 1520
    },
    {
      "epoch": 0.38941206413845764,
      "grad_norm": 0.0041536386124789715,
      "learning_rate": 1.2216849071010437e-05,
      "loss": 0.0002,
      "step": 1530
    },
    {
      "epoch": 0.39195724102825147,
      "grad_norm": 0.003991751931607723,
      "learning_rate": 1.216594553321456e-05,
      "loss": 0.0002,
      "step": 1540
    },
    {
      "epoch": 0.3945024179180453,
      "grad_norm": 0.001980753615498543,
      "learning_rate": 1.2115041995418682e-05,
      "loss": 0.0001,
      "step": 1550
    },
    {
      "epoch": 0.39704759480783913,
      "grad_norm": 0.003139122622087598,
      "learning_rate": 1.2069228811402394e-05,
      "loss": 0.0887,
      "step": 1560
    },
    {
      "epoch": 0.39959277169763296,
      "grad_norm": 0.0024472337681800127,
      "learning_rate": 1.2018325273606517e-05,
      "loss": 0.0001,
      "step": 1570
    },
    {
      "epoch": 0.40213794858742685,
      "grad_norm": 0.0033784753177314997,
      "learning_rate": 1.196742173581064e-05,
      "loss": 0.0001,
      "step": 1580
    },
    {
      "epoch": 0.4046831254772207,
      "grad_norm": 0.002773377811536193,
      "learning_rate": 1.1916518198014764e-05,
      "loss": 0.0001,
      "step": 1590
    },
    {
      "epoch": 0.4072283023670145,
      "grad_norm": 0.0016327251214534044,
      "learning_rate": 1.1865614660218887e-05,
      "loss": 0.0001,
      "step": 1600
    },
    {
      "epoch": 0.40977347925680835,
      "grad_norm": 0.00215469254180789,
      "learning_rate": 1.181471112242301e-05,
      "loss": 0.0001,
      "step": 1610
    },
    {
      "epoch": 0.4123186561466022,
      "grad_norm": 0.0019971393048763275,
      "learning_rate": 1.176380758462713e-05,
      "loss": 0.0001,
      "step": 1620
    },
    {
      "epoch": 0.414863833036396,
      "grad_norm": 0.0026523428969085217,
      "learning_rate": 1.1712904046831254e-05,
      "loss": 0.0001,
      "step": 1630
    },
    {
      "epoch": 0.41740900992618984,
      "grad_norm": 0.0027416048105806112,
      "learning_rate": 1.1662000509035378e-05,
      "loss": 0.0001,
      "step": 1640
    },
    {
      "epoch": 0.41995418681598373,
      "grad_norm": 0.002829228760674596,
      "learning_rate": 1.1611096971239501e-05,
      "loss": 0.0001,
      "step": 1650
    },
    {
      "epoch": 0.42249936370577756,
      "grad_norm": 0.002354399301111698,
      "learning_rate": 1.1560193433443624e-05,
      "loss": 0.0001,
      "step": 1660
    },
    {
      "epoch": 0.4250445405955714,
      "grad_norm": 0.0031309037003666162,
      "learning_rate": 1.1509289895647748e-05,
      "loss": 0.0001,
      "step": 1670
    },
    {
      "epoch": 0.42758971748536523,
      "grad_norm": 0.0022360561415553093,
      "learning_rate": 1.1458386357851871e-05,
      "loss": 0.0001,
      "step": 1680
    },
    {
      "epoch": 0.43013489437515906,
      "grad_norm": 0.0019807247444987297,
      "learning_rate": 1.1407482820055994e-05,
      "loss": 0.0001,
      "step": 1690
    },
    {
      "epoch": 0.4326800712649529,
      "grad_norm": 0.0022629480808973312,
      "learning_rate": 1.1356579282260118e-05,
      "loss": 0.0001,
      "step": 1700
    },
    {
      "epoch": 0.4352252481547468,
      "grad_norm": 0.0012507057981565595,
      "learning_rate": 1.1305675744464241e-05,
      "loss": 0.0001,
      "step": 1710
    },
    {
      "epoch": 0.4377704250445406,
      "grad_norm": 0.0017115315422415733,
      "learning_rate": 1.1254772206668364e-05,
      "loss": 0.0001,
      "step": 1720
    },
    {
      "epoch": 0.44031560193433444,
      "grad_norm": 0.0020140695851296186,
      "learning_rate": 1.1203868668872488e-05,
      "loss": 0.0001,
      "step": 1730
    },
    {
      "epoch": 0.4428607788241283,
      "grad_norm": 0.0025006637442857027,
      "learning_rate": 1.1152965131076611e-05,
      "loss": 0.0001,
      "step": 1740
    },
    {
      "epoch": 0.4454059557139221,
      "grad_norm": 0.0013305902248248458,
      "learning_rate": 1.1102061593280733e-05,
      "loss": 0.0001,
      "step": 1750
    },
    {
      "epoch": 0.44795113260371594,
      "grad_norm": 0.0019013716373592615,
      "learning_rate": 1.1051158055484856e-05,
      "loss": 0.0001,
      "step": 1760
    },
    {
      "epoch": 0.4504963094935098,
      "grad_norm": 0.002129233442246914,
      "learning_rate": 1.100025451768898e-05,
      "loss": 0.0006,
      "step": 1770
    },
    {
      "epoch": 0.45304148638330366,
      "grad_norm": 0.0045149000361561775,
      "learning_rate": 1.0949350979893103e-05,
      "loss": 0.0001,
      "step": 1780
    },
    {
      "epoch": 0.4555866632730975,
      "grad_norm": 0.0020331996493041515,
      "learning_rate": 1.0898447442097226e-05,
      "loss": 0.0796,
      "step": 1790
    },
    {
      "epoch": 0.4581318401628913,
      "grad_norm": 0.017583250999450684,
      "learning_rate": 1.084754390430135e-05,
      "loss": 0.0001,
      "step": 1800
    },
    {
      "epoch": 0.46067701705268516,
      "grad_norm": 0.006071230862289667,
      "learning_rate": 1.080173072028506e-05,
      "loss": 0.0945,
      "step": 1810
    },
    {
      "epoch": 0.463222193942479,
      "grad_norm": 0.0030575538985431194,
      "learning_rate": 1.0750827182489184e-05,
      "loss": 0.0909,
      "step": 1820
    },
    {
      "epoch": 0.4657673708322728,
      "grad_norm": 0.001737319165840745,
      "learning_rate": 1.0699923644693307e-05,
      "loss": 0.0001,
      "step": 1830
    },
    {
      "epoch": 0.4683125477220667,
      "grad_norm": 0.0014996016398072243,
      "learning_rate": 1.064902010689743e-05,
      "loss": 0.0001,
      "step": 1840
    },
    {
      "epoch": 0.47085772461186054,
      "grad_norm": 0.003583104582503438,
      "learning_rate": 1.0598116569101554e-05,
      "loss": 0.0001,
      "step": 1850
    },
    {
      "epoch": 0.47340290150165437,
      "grad_norm": 0.0022766590118408203,
      "learning_rate": 1.0547213031305677e-05,
      "loss": 0.0001,
      "step": 1860
    },
    {
      "epoch": 0.4759480783914482,
      "grad_norm": 0.0017893387703225017,
      "learning_rate": 1.04963094935098e-05,
      "loss": 0.0001,
      "step": 1870
    },
    {
      "epoch": 0.47849325528124204,
      "grad_norm": 0.0009599067852832377,
      "learning_rate": 1.0445405955713924e-05,
      "loss": 0.0001,
      "step": 1880
    },
    {
      "epoch": 0.48103843217103587,
      "grad_norm": 0.0021839155815541744,
      "learning_rate": 1.0394502417918047e-05,
      "loss": 0.0001,
      "step": 1890
    },
    {
      "epoch": 0.4835836090608297,
      "grad_norm": 0.0019440202740952373,
      "learning_rate": 1.034359888012217e-05,
      "loss": 0.0001,
      "step": 1900
    },
    {
      "epoch": 0.4861287859506236,
      "grad_norm": 0.0016198210651054978,
      "learning_rate": 1.0292695342326294e-05,
      "loss": 0.0001,
      "step": 1910
    },
    {
      "epoch": 0.4886739628404174,
      "grad_norm": 0.001645697862841189,
      "learning_rate": 1.0241791804530417e-05,
      "loss": 0.0001,
      "step": 1920
    },
    {
      "epoch": 0.49121913973021125,
      "grad_norm": 0.0017762539209797978,
      "learning_rate": 1.019088826673454e-05,
      "loss": 0.0001,
      "step": 1930
    },
    {
      "epoch": 0.4937643166200051,
      "grad_norm": 0.001143879722803831,
      "learning_rate": 1.013998472893866e-05,
      "loss": 0.0001,
      "step": 1940
    },
    {
      "epoch": 0.4963094935097989,
      "grad_norm": 0.0030762054957449436,
      "learning_rate": 1.0089081191142784e-05,
      "loss": 0.0002,
      "step": 1950
    },
    {
      "epoch": 0.49885467039959275,
      "grad_norm": 0.002346763852983713,
      "learning_rate": 1.0038177653346907e-05,
      "loss": 0.0273,
      "step": 1960
    },
    {
      "epoch": 0.5013998472893866,
      "grad_norm": 0.0023000522051006556,
      "learning_rate": 9.98727411555103e-06,
      "loss": 0.0001,
      "step": 1970
    },
    {
      "epoch": 0.5039450241791804,
      "grad_norm": 0.005768895149230957,
      "learning_rate": 9.936370577755154e-06,
      "loss": 0.0001,
      "step": 1980
    },
    {
      "epoch": 0.5064902010689742,
      "grad_norm": 0.0022633979097008705,
      "learning_rate": 9.885467039959278e-06,
      "loss": 0.0001,
      "step": 1990
    },
    {
      "epoch": 0.5090353779587682,
      "grad_norm": 0.0012884840834885836,
      "learning_rate": 9.834563502163401e-06,
      "loss": 0.0001,
      "step": 2000
    },
    {
      "epoch": 0.511580554848562,
      "grad_norm": 0.0013043744256719947,
      "learning_rate": 9.783659964367524e-06,
      "loss": 0.0135,
      "step": 2010
    },
    {
      "epoch": 0.5141257317383559,
      "grad_norm": 0.0010594085324555635,
      "learning_rate": 9.732756426571648e-06,
      "loss": 0.0062,
      "step": 2020
    },
    {
      "epoch": 0.5166709086281497,
      "grad_norm": 0.0015901685692369938,
      "learning_rate": 9.681852888775771e-06,
      "loss": 0.0002,
      "step": 2030
    },
    {
      "epoch": 0.5192160855179435,
      "grad_norm": 0.0011006688000634313,
      "learning_rate": 9.630949350979893e-06,
      "loss": 0.0001,
      "step": 2040
    },
    {
      "epoch": 0.5217612624077373,
      "grad_norm": 0.0011772868456318974,
      "learning_rate": 9.580045813184016e-06,
      "loss": 0.0001,
      "step": 2050
    },
    {
      "epoch": 0.5243064392975312,
      "grad_norm": 0.001817968557588756,
      "learning_rate": 9.52914227538814e-06,
      "loss": 0.0001,
      "step": 2060
    },
    {
      "epoch": 0.526851616187325,
      "grad_norm": 0.002071988768875599,
      "learning_rate": 9.478238737592263e-06,
      "loss": 0.0001,
      "step": 2070
    },
    {
      "epoch": 0.5293967930771188,
      "grad_norm": 0.001170027651824057,
      "learning_rate": 9.427335199796386e-06,
      "loss": 0.0001,
      "step": 2080
    },
    {
      "epoch": 0.5319419699669127,
      "grad_norm": 0.0017318407772108912,
      "learning_rate": 9.37643166200051e-06,
      "loss": 0.0001,
      "step": 2090
    },
    {
      "epoch": 0.5344871468567065,
      "grad_norm": 0.001083111623302102,
      "learning_rate": 9.325528124204633e-06,
      "loss": 0.0001,
      "step": 2100
    },
    {
      "epoch": 0.5370323237465003,
      "grad_norm": 0.0010819979943335056,
      "learning_rate": 9.274624586408756e-06,
      "loss": 0.0001,
      "step": 2110
    },
    {
      "epoch": 0.5395775006362942,
      "grad_norm": 0.0009692520834505558,
      "learning_rate": 9.22372104861288e-06,
      "loss": 0.0001,
      "step": 2120
    },
    {
      "epoch": 0.5421226775260881,
      "grad_norm": 0.0025161204393953085,
      "learning_rate": 9.172817510817003e-06,
      "loss": 0.0001,
      "step": 2130
    },
    {
      "epoch": 0.544667854415882,
      "grad_norm": 0.0021443646401166916,
      "learning_rate": 9.121913973021126e-06,
      "loss": 0.0001,
      "step": 2140
    },
    {
      "epoch": 0.5472130313056758,
      "grad_norm": 0.0021855556406080723,
      "learning_rate": 9.07101043522525e-06,
      "loss": 0.0001,
      "step": 2150
    },
    {
      "epoch": 0.5497582081954696,
      "grad_norm": 0.0010357104474678636,
      "learning_rate": 9.020106897429373e-06,
      "loss": 0.0001,
      "step": 2160
    },
    {
      "epoch": 0.5523033850852634,
      "grad_norm": 0.0017002122476696968,
      "learning_rate": 8.969203359633495e-06,
      "loss": 0.0001,
      "step": 2170
    },
    {
      "epoch": 0.5548485619750573,
      "grad_norm": 0.0011723926290869713,
      "learning_rate": 8.918299821837618e-06,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 0.5573937388648511,
      "grad_norm": 0.0019397098803892732,
      "learning_rate": 8.867396284041741e-06,
      "loss": 0.0001,
      "step": 2190
    },
    {
      "epoch": 0.5599389157546449,
      "grad_norm": 0.0008442078251391649,
      "learning_rate": 8.816492746245865e-06,
      "loss": 0.0001,
      "step": 2200
    },
    {
      "epoch": 0.5624840926444388,
      "grad_norm": 0.0015826760791242123,
      "learning_rate": 8.765589208449988e-06,
      "loss": 0.0001,
      "step": 2210
    },
    {
      "epoch": 0.5650292695342326,
      "grad_norm": 0.0011323165381327271,
      "learning_rate": 8.714685670654112e-06,
      "loss": 0.0001,
      "step": 2220
    },
    {
      "epoch": 0.5675744464240264,
      "grad_norm": 0.0015945082996040583,
      "learning_rate": 8.663782132858233e-06,
      "loss": 0.0001,
      "step": 2230
    },
    {
      "epoch": 0.5701196233138203,
      "grad_norm": 0.001904914970509708,
      "learning_rate": 8.612878595062357e-06,
      "loss": 0.0001,
      "step": 2240
    },
    {
      "epoch": 0.5726648002036141,
      "grad_norm": 0.0018891595536842942,
      "learning_rate": 8.56197505726648e-06,
      "loss": 0.0001,
      "step": 2250
    },
    {
      "epoch": 0.575209977093408,
      "grad_norm": 0.0022682235576212406,
      "learning_rate": 8.511071519470603e-06,
      "loss": 0.0,
      "step": 2260
    },
    {
      "epoch": 0.5777551539832019,
      "grad_norm": 0.0011238189181312919,
      "learning_rate": 8.460167981674727e-06,
      "loss": 0.0001,
      "step": 2270
    },
    {
      "epoch": 0.5803003308729957,
      "grad_norm": 0.0008810677682049572,
      "learning_rate": 8.40926444387885e-06,
      "loss": 0.0001,
      "step": 2280
    },
    {
      "epoch": 0.5828455077627895,
      "grad_norm": 0.0012032730737701058,
      "learning_rate": 8.358360906082973e-06,
      "loss": 0.0,
      "step": 2290
    },
    {
      "epoch": 0.5853906846525834,
      "grad_norm": 0.0011313700815662742,
      "learning_rate": 8.307457368287097e-06,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.5879358615423772,
      "grad_norm": 0.000998381758108735,
      "learning_rate": 8.25655383049122e-06,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 0.590481038432171,
      "grad_norm": 0.0012784118298441172,
      "learning_rate": 8.205650292695343e-06,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 0.5930262153219649,
      "grad_norm": 0.0009603716316632926,
      "learning_rate": 8.154746754899467e-06,
      "loss": 0.0,
      "step": 2330
    },
    {
      "epoch": 0.5955713922117587,
      "grad_norm": 0.000847119081299752,
      "learning_rate": 8.10384321710359e-06,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 0.5981165691015525,
      "grad_norm": 0.0012771512847393751,
      "learning_rate": 8.052939679307714e-06,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 0.6006617459913464,
      "grad_norm": 0.0011223353212699294,
      "learning_rate": 8.002036141511835e-06,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 0.6032069228811402,
      "grad_norm": 0.0014906198484823108,
      "learning_rate": 7.951132603715959e-06,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 0.605752099770934,
      "grad_norm": 0.0010504720266908407,
      "learning_rate": 7.900229065920082e-06,
      "loss": 0.0,
      "step": 2380
    },
    {
      "epoch": 0.608297276660728,
      "grad_norm": 0.0011519581312313676,
      "learning_rate": 7.849325528124205e-06,
      "loss": 0.0,
      "step": 2390
    },
    {
      "epoch": 0.6108424535505218,
      "grad_norm": 0.009035250172019005,
      "learning_rate": 7.798421990328329e-06,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 0.6133876304403156,
      "grad_norm": 0.000920405553188175,
      "learning_rate": 7.747518452532452e-06,
      "loss": 0.0,
      "step": 2410
    },
    {
      "epoch": 0.6159328073301095,
      "grad_norm": 0.0009935382986441255,
      "learning_rate": 7.696614914736574e-06,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 0.6184779842199033,
      "grad_norm": 0.0012571725528687239,
      "learning_rate": 7.645711376940697e-06,
      "loss": 0.0,
      "step": 2430
    },
    {
      "epoch": 0.6210231611096971,
      "grad_norm": 0.001240264973603189,
      "learning_rate": 7.594807839144821e-06,
      "loss": 0.0,
      "step": 2440
    },
    {
      "epoch": 0.623568337999491,
      "grad_norm": 0.0008853251929394901,
      "learning_rate": 7.543904301348945e-06,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 0.6261135148892848,
      "grad_norm": 0.0017488623270764947,
      "learning_rate": 7.493000763553068e-06,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 0.6286586917790786,
      "grad_norm": 0.0016304024029523134,
      "learning_rate": 7.442097225757191e-06,
      "loss": 0.1296,
      "step": 2470
    },
    {
      "epoch": 0.6312038686688725,
      "grad_norm": 0.0013099302304908633,
      "learning_rate": 7.391193687961315e-06,
      "loss": 0.0001,
      "step": 2480
    },
    {
      "epoch": 0.6337490455586663,
      "grad_norm": 0.0020673591643571854,
      "learning_rate": 7.3402901501654364e-06,
      "loss": 0.0001,
      "step": 2490
    },
    {
      "epoch": 0.6362942224484601,
      "grad_norm": 0.003037361428141594,
      "learning_rate": 7.28938661236956e-06,
      "loss": 0.0001,
      "step": 2500
    },
    {
      "epoch": 0.638839399338254,
      "grad_norm": 0.0022820988669991493,
      "learning_rate": 7.238483074573683e-06,
      "loss": 0.0001,
      "step": 2510
    },
    {
      "epoch": 0.6413845762280479,
      "grad_norm": 0.0028830335941165686,
      "learning_rate": 7.1875795367778065e-06,
      "loss": 0.0001,
      "step": 2520
    },
    {
      "epoch": 0.6439297531178417,
      "grad_norm": 0.0021064123138785362,
      "learning_rate": 7.13667599898193e-06,
      "loss": 0.0001,
      "step": 2530
    },
    {
      "epoch": 0.6464749300076356,
      "grad_norm": 0.0022204630076885223,
      "learning_rate": 7.085772461186053e-06,
      "loss": 0.0001,
      "step": 2540
    },
    {
      "epoch": 0.6490201068974294,
      "grad_norm": 0.00250835157930851,
      "learning_rate": 7.034868923390176e-06,
      "loss": 0.0001,
      "step": 2550
    },
    {
      "epoch": 0.6515652837872232,
      "grad_norm": 0.002005959628149867,
      "learning_rate": 6.983965385594299e-06,
      "loss": 0.0001,
      "step": 2560
    },
    {
      "epoch": 0.6541104606770171,
      "grad_norm": 0.0020421200897544622,
      "learning_rate": 6.9330618477984225e-06,
      "loss": 0.0001,
      "step": 2570
    },
    {
      "epoch": 0.6566556375668109,
      "grad_norm": 0.0017174605745822191,
      "learning_rate": 6.882158310002546e-06,
      "loss": 0.0001,
      "step": 2580
    },
    {
      "epoch": 0.6592008144566047,
      "grad_norm": 0.0012468621134757996,
      "learning_rate": 6.831254772206669e-06,
      "loss": 0.0001,
      "step": 2590
    },
    {
      "epoch": 0.6617459913463986,
      "grad_norm": 0.001550618908368051,
      "learning_rate": 6.780351234410793e-06,
      "loss": 0.0001,
      "step": 2600
    },
    {
      "epoch": 0.6642911682361924,
      "grad_norm": 0.0033338472712785006,
      "learning_rate": 6.729447696614916e-06,
      "loss": 0.1079,
      "step": 2610
    },
    {
      "epoch": 0.6668363451259862,
      "grad_norm": 0.009581035934388638,
      "learning_rate": 6.678544158819038e-06,
      "loss": 0.0002,
      "step": 2620
    },
    {
      "epoch": 0.66938152201578,
      "grad_norm": 0.007554284762591124,
      "learning_rate": 6.627640621023161e-06,
      "loss": 0.0002,
      "step": 2630
    },
    {
      "epoch": 0.6719266989055739,
      "grad_norm": 0.007488548755645752,
      "learning_rate": 6.576737083227284e-06,
      "loss": 0.0002,
      "step": 2640
    },
    {
      "epoch": 0.6744718757953678,
      "grad_norm": 0.00595172168686986,
      "learning_rate": 6.525833545431408e-06,
      "loss": 0.0002,
      "step": 2650
    },
    {
      "epoch": 0.6770170526851617,
      "grad_norm": 0.0060608950443565845,
      "learning_rate": 6.474930007635531e-06,
      "loss": 0.0001,
      "step": 2660
    },
    {
      "epoch": 0.6795622295749555,
      "grad_norm": 0.001138419727794826,
      "learning_rate": 6.4240264698396545e-06,
      "loss": 0.0001,
      "step": 2670
    },
    {
      "epoch": 0.6821074064647493,
      "grad_norm": 0.0035116788931190968,
      "learning_rate": 6.373122932043777e-06,
      "loss": 0.0001,
      "step": 2680
    },
    {
      "epoch": 0.6846525833545432,
      "grad_norm": 0.0026138974353671074,
      "learning_rate": 6.3222193942479e-06,
      "loss": 0.0001,
      "step": 2690
    },
    {
      "epoch": 0.687197760244337,
      "grad_norm": 0.0024622755590826273,
      "learning_rate": 6.271315856452024e-06,
      "loss": 0.0001,
      "step": 2700
    },
    {
      "epoch": 0.6897429371341308,
      "grad_norm": 0.0020288126543164253,
      "learning_rate": 6.220412318656147e-06,
      "loss": 0.0001,
      "step": 2710
    },
    {
      "epoch": 0.6922881140239247,
      "grad_norm": 0.0022001969628036022,
      "learning_rate": 6.1695087808602704e-06,
      "loss": 0.0001,
      "step": 2720
    },
    {
      "epoch": 0.6948332909137185,
      "grad_norm": 0.0015249864663928747,
      "learning_rate": 6.118605243064394e-06,
      "loss": 0.0001,
      "step": 2730
    },
    {
      "epoch": 0.6973784678035123,
      "grad_norm": 0.0012659153435379267,
      "learning_rate": 6.067701705268517e-06,
      "loss": 0.0001,
      "step": 2740
    },
    {
      "epoch": 0.6999236446933061,
      "grad_norm": 0.002077964600175619,
      "learning_rate": 6.01679816747264e-06,
      "loss": 0.0001,
      "step": 2750
    },
    {
      "epoch": 0.7024688215831,
      "grad_norm": 0.0038241222500801086,
      "learning_rate": 5.965894629676763e-06,
      "loss": 0.0001,
      "step": 2760
    },
    {
      "epoch": 0.7050139984728939,
      "grad_norm": 0.0021587959490716457,
      "learning_rate": 5.914991091880886e-06,
      "loss": 0.0001,
      "step": 2770
    },
    {
      "epoch": 0.7075591753626878,
      "grad_norm": 0.0029398947954177856,
      "learning_rate": 5.86408755408501e-06,
      "loss": 0.0001,
      "step": 2780
    },
    {
      "epoch": 0.7101043522524816,
      "grad_norm": 0.0027539057191461325,
      "learning_rate": 5.813184016289133e-06,
      "loss": 0.0001,
      "step": 2790
    },
    {
      "epoch": 0.7126495291422754,
      "grad_norm": 0.0017412536544725299,
      "learning_rate": 5.7622804784932565e-06,
      "loss": 0.0001,
      "step": 2800
    },
    {
      "epoch": 0.7151947060320692,
      "grad_norm": 0.0010996556375175714,
      "learning_rate": 5.711376940697378e-06,
      "loss": 0.0001,
      "step": 2810
    },
    {
      "epoch": 0.7177398829218631,
      "grad_norm": 0.002754737390205264,
      "learning_rate": 5.6604734029015015e-06,
      "loss": 0.0001,
      "step": 2820
    },
    {
      "epoch": 0.7202850598116569,
      "grad_norm": 0.002395790768787265,
      "learning_rate": 5.609569865105625e-06,
      "loss": 0.0001,
      "step": 2830
    },
    {
      "epoch": 0.7228302367014507,
      "grad_norm": 0.0034311336930841208,
      "learning_rate": 5.558666327309748e-06,
      "loss": 0.0001,
      "step": 2840
    },
    {
      "epoch": 0.7253754135912446,
      "grad_norm": 0.003049014136195183,
      "learning_rate": 5.507762789513872e-06,
      "loss": 0.0001,
      "step": 2850
    },
    {
      "epoch": 0.7279205904810384,
      "grad_norm": 0.0007594540365971625,
      "learning_rate": 5.456859251717995e-06,
      "loss": 0.0851,
      "step": 2860
    },
    {
      "epoch": 0.7304657673708322,
      "grad_norm": 0.0036532736849039793,
      "learning_rate": 5.4059557139221175e-06,
      "loss": 0.1042,
      "step": 2870
    },
    {
      "epoch": 0.7330109442606261,
      "grad_norm": 0.00550879305228591,
      "learning_rate": 5.355052176126241e-06,
      "loss": 0.0002,
      "step": 2880
    },
    {
      "epoch": 0.7355561211504199,
      "grad_norm": 0.005880109965801239,
      "learning_rate": 5.304148638330364e-06,
      "loss": 0.0002,
      "step": 2890
    },
    {
      "epoch": 0.7381012980402138,
      "grad_norm": 0.009121260605752468,
      "learning_rate": 5.253245100534488e-06,
      "loss": 0.0022,
      "step": 2900
    },
    {
      "epoch": 0.7406464749300077,
      "grad_norm": 0.005350182764232159,
      "learning_rate": 5.202341562738611e-06,
      "loss": 0.0002,
      "step": 2910
    },
    {
      "epoch": 0.7431916518198015,
      "grad_norm": 0.002056763507425785,
      "learning_rate": 5.151438024942734e-06,
      "loss": 0.0001,
      "step": 2920
    },
    {
      "epoch": 0.7457368287095953,
      "grad_norm": 0.003930931445211172,
      "learning_rate": 5.100534487146858e-06,
      "loss": 0.0001,
      "step": 2930
    },
    {
      "epoch": 0.7482820055993892,
      "grad_norm": 0.006651034578680992,
      "learning_rate": 5.04963094935098e-06,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 0.750827182489183,
      "grad_norm": 0.002231618855148554,
      "learning_rate": 4.998727411555104e-06,
      "loss": 0.0001,
      "step": 2950
    },
    {
      "epoch": 0.7533723593789768,
      "grad_norm": 0.0018406235612928867,
      "learning_rate": 4.947823873759227e-06,
      "loss": 0.0001,
      "step": 2960
    },
    {
      "epoch": 0.7559175362687707,
      "grad_norm": 0.003968764096498489,
      "learning_rate": 4.89692033596335e-06,
      "loss": 0.0001,
      "step": 2970
    },
    {
      "epoch": 0.7584627131585645,
      "grad_norm": 0.0036620290484279394,
      "learning_rate": 4.846016798167474e-06,
      "loss": 0.0001,
      "step": 2980
    },
    {
      "epoch": 0.7610078900483583,
      "grad_norm": 0.0016710333293303847,
      "learning_rate": 4.795113260371596e-06,
      "loss": 0.0001,
      "step": 2990
    },
    {
      "epoch": 0.7635530669381522,
      "grad_norm": 0.002425447339192033,
      "learning_rate": 4.7442097225757196e-06,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 0.766098243827946,
      "grad_norm": 0.0033540744334459305,
      "learning_rate": 4.693306184779843e-06,
      "loss": 0.0001,
      "step": 3010
    },
    {
      "epoch": 0.7686434207177398,
      "grad_norm": 0.0025995937176048756,
      "learning_rate": 4.6424026469839654e-06,
      "loss": 0.0001,
      "step": 3020
    },
    {
      "epoch": 0.7711885976075338,
      "grad_norm": 0.0019030527910217643,
      "learning_rate": 4.591499109188089e-06,
      "loss": 0.0001,
      "step": 3030
    },
    {
      "epoch": 0.7737337744973276,
      "grad_norm": 0.0024262797087430954,
      "learning_rate": 4.540595571392212e-06,
      "loss": 0.0001,
      "step": 3040
    },
    {
      "epoch": 0.7762789513871214,
      "grad_norm": 0.0030029197223484516,
      "learning_rate": 4.489692033596335e-06,
      "loss": 0.0001,
      "step": 3050
    },
    {
      "epoch": 0.7788241282769153,
      "grad_norm": 0.0015598400495946407,
      "learning_rate": 4.438788495800458e-06,
      "loss": 0.0001,
      "step": 3060
    },
    {
      "epoch": 0.7813693051667091,
      "grad_norm": 0.003166493959724903,
      "learning_rate": 4.387884958004581e-06,
      "loss": 0.0001,
      "step": 3070
    },
    {
      "epoch": 0.7839144820565029,
      "grad_norm": 0.006202188320457935,
      "learning_rate": 4.336981420208705e-06,
      "loss": 0.0001,
      "step": 3080
    },
    {
      "epoch": 0.7864596589462968,
      "grad_norm": 0.002050644950941205,
      "learning_rate": 4.286077882412828e-06,
      "loss": 0.0001,
      "step": 3090
    },
    {
      "epoch": 0.7890048358360906,
      "grad_norm": 0.0022437048610299826,
      "learning_rate": 4.2351743446169515e-06,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 0.7915500127258844,
      "grad_norm": 0.002203185111284256,
      "learning_rate": 4.184270806821075e-06,
      "loss": 0.0001,
      "step": 3110
    },
    {
      "epoch": 0.7940951896156783,
      "grad_norm": 0.002333597978577018,
      "learning_rate": 4.133367269025197e-06,
      "loss": 0.0001,
      "step": 3120
    },
    {
      "epoch": 0.7966403665054721,
      "grad_norm": 0.004315425641834736,
      "learning_rate": 4.082463731229321e-06,
      "loss": 0.0001,
      "step": 3130
    },
    {
      "epoch": 0.7991855433952659,
      "grad_norm": 0.0038702895399183035,
      "learning_rate": 4.031560193433444e-06,
      "loss": 0.0001,
      "step": 3140
    },
    {
      "epoch": 0.8017307202850598,
      "grad_norm": 0.0013697107788175344,
      "learning_rate": 3.980656655637567e-06,
      "loss": 0.0001,
      "step": 3150
    },
    {
      "epoch": 0.8042758971748537,
      "grad_norm": 0.001863385085016489,
      "learning_rate": 3.92975311784169e-06,
      "loss": 0.0001,
      "step": 3160
    },
    {
      "epoch": 0.8068210740646475,
      "grad_norm": 0.002783833770081401,
      "learning_rate": 3.878849580045813e-06,
      "loss": 0.0001,
      "step": 3170
    },
    {
      "epoch": 0.8093662509544414,
      "grad_norm": 0.0017692347755655646,
      "learning_rate": 3.827946042249937e-06,
      "loss": 0.0001,
      "step": 3180
    },
    {
      "epoch": 0.8119114278442352,
      "grad_norm": 0.0010116372723132372,
      "learning_rate": 3.7770425044540597e-06,
      "loss": 0.0001,
      "step": 3190
    },
    {
      "epoch": 0.814456604734029,
      "grad_norm": 0.0012360145337879658,
      "learning_rate": 3.726138966658183e-06,
      "loss": 0.0001,
      "step": 3200
    },
    {
      "epoch": 0.8170017816238229,
      "grad_norm": 0.001853917958214879,
      "learning_rate": 3.675235428862306e-06,
      "loss": 0.0001,
      "step": 3210
    },
    {
      "epoch": 0.8195469585136167,
      "grad_norm": 0.003564570564776659,
      "learning_rate": 3.6243318910664293e-06,
      "loss": 0.0001,
      "step": 3220
    },
    {
      "epoch": 0.8220921354034105,
      "grad_norm": 0.001633998821489513,
      "learning_rate": 3.5734283532705527e-06,
      "loss": 0.0001,
      "step": 3230
    },
    {
      "epoch": 0.8246373122932044,
      "grad_norm": 0.0029235747642815113,
      "learning_rate": 3.5225248154746756e-06,
      "loss": 0.0001,
      "step": 3240
    },
    {
      "epoch": 0.8271824891829982,
      "grad_norm": 0.0021726873237639666,
      "learning_rate": 3.471621277678799e-06,
      "loss": 0.0001,
      "step": 3250
    },
    {
      "epoch": 0.829727666072792,
      "grad_norm": 0.0011768401600420475,
      "learning_rate": 3.4207177398829224e-06,
      "loss": 0.0001,
      "step": 3260
    },
    {
      "epoch": 0.8322728429625859,
      "grad_norm": 0.001823459635488689,
      "learning_rate": 3.3698142020870457e-06,
      "loss": 0.0001,
      "step": 3270
    },
    {
      "epoch": 0.8348180198523797,
      "grad_norm": 0.0007378547452390194,
      "learning_rate": 3.3189106642911682e-06,
      "loss": 0.0001,
      "step": 3280
    },
    {
      "epoch": 0.8373631967421736,
      "grad_norm": 0.0011710586259141564,
      "learning_rate": 3.2680071264952916e-06,
      "loss": 0.0001,
      "step": 3290
    },
    {
      "epoch": 0.8399083736319675,
      "grad_norm": 0.0015041736187413335,
      "learning_rate": 3.217103588699415e-06,
      "loss": 0.0001,
      "step": 3300
    },
    {
      "epoch": 0.8424535505217613,
      "grad_norm": 0.002165402751415968,
      "learning_rate": 3.166200050903538e-06,
      "loss": 0.0001,
      "step": 3310
    },
    {
      "epoch": 0.8449987274115551,
      "grad_norm": 0.002837883774191141,
      "learning_rate": 3.1152965131076613e-06,
      "loss": 0.0001,
      "step": 3320
    },
    {
      "epoch": 0.847543904301349,
      "grad_norm": 0.0013672838686034083,
      "learning_rate": 3.0643929753117846e-06,
      "loss": 0.0001,
      "step": 3330
    },
    {
      "epoch": 0.8500890811911428,
      "grad_norm": 0.002749995095655322,
      "learning_rate": 3.0134894375159076e-06,
      "loss": 0.0001,
      "step": 3340
    },
    {
      "epoch": 0.8526342580809366,
      "grad_norm": 0.0011029246961697936,
      "learning_rate": 2.962585899720031e-06,
      "loss": 0.0001,
      "step": 3350
    },
    {
      "epoch": 0.8551794349707305,
      "grad_norm": 0.00101805932354182,
      "learning_rate": 2.911682361924154e-06,
      "loss": 0.0001,
      "step": 3360
    },
    {
      "epoch": 0.8577246118605243,
      "grad_norm": 0.0015438770642504096,
      "learning_rate": 2.860778824128277e-06,
      "loss": 0.0001,
      "step": 3370
    },
    {
      "epoch": 0.8602697887503181,
      "grad_norm": 0.001821451005525887,
      "learning_rate": 2.8098752863324e-06,
      "loss": 0.0001,
      "step": 3380
    },
    {
      "epoch": 0.862814965640112,
      "grad_norm": 0.0019092099973931909,
      "learning_rate": 2.7589717485365236e-06,
      "loss": 0.0001,
      "step": 3390
    },
    {
      "epoch": 0.8653601425299058,
      "grad_norm": 0.0016151000745594501,
      "learning_rate": 2.708068210740647e-06,
      "loss": 0.0001,
      "step": 3400
    },
    {
      "epoch": 0.8679053194196996,
      "grad_norm": 0.0015071732923388481,
      "learning_rate": 2.65716467294477e-06,
      "loss": 0.0001,
      "step": 3410
    },
    {
      "epoch": 0.8704504963094936,
      "grad_norm": 0.001395444036461413,
      "learning_rate": 2.6062611351488932e-06,
      "loss": 0.0001,
      "step": 3420
    },
    {
      "epoch": 0.8729956731992874,
      "grad_norm": 0.0023495617788285017,
      "learning_rate": 2.5553575973530166e-06,
      "loss": 0.0001,
      "step": 3430
    },
    {
      "epoch": 0.8755408500890812,
      "grad_norm": 0.0024433485232293606,
      "learning_rate": 2.504454059557139e-06,
      "loss": 0.1033,
      "step": 3440
    },
    {
      "epoch": 0.8780860269788751,
      "grad_norm": 0.0012782261474058032,
      "learning_rate": 2.4535505217612625e-06,
      "loss": 0.0001,
      "step": 3450
    },
    {
      "epoch": 0.8806312038686689,
      "grad_norm": 0.003892210777848959,
      "learning_rate": 2.402646983965386e-06,
      "loss": 0.0001,
      "step": 3460
    },
    {
      "epoch": 0.8831763807584627,
      "grad_norm": 0.002625910798087716,
      "learning_rate": 2.351743446169509e-06,
      "loss": 0.0001,
      "step": 3470
    },
    {
      "epoch": 0.8857215576482566,
      "grad_norm": 0.0013344620820134878,
      "learning_rate": 2.300839908373632e-06,
      "loss": 0.0001,
      "step": 3480
    },
    {
      "epoch": 0.8882667345380504,
      "grad_norm": 0.00221369625069201,
      "learning_rate": 2.249936370577755e-06,
      "loss": 0.0001,
      "step": 3490
    },
    {
      "epoch": 0.8908119114278442,
      "grad_norm": 0.00302304420620203,
      "learning_rate": 2.1990328327818785e-06,
      "loss": 0.1003,
      "step": 3500
    },
    {
      "epoch": 0.893357088317638,
      "grad_norm": 0.0045974585227668285,
      "learning_rate": 2.148129294986002e-06,
      "loss": 0.0002,
      "step": 3510
    },
    {
      "epoch": 0.8959022652074319,
      "grad_norm": 0.0029602739959955215,
      "learning_rate": 2.097225757190125e-06,
      "loss": 0.0002,
      "step": 3520
    },
    {
      "epoch": 0.8984474420972257,
      "grad_norm": 0.004538474604487419,
      "learning_rate": 2.046322219394248e-06,
      "loss": 0.0001,
      "step": 3530
    },
    {
      "epoch": 0.9009926189870195,
      "grad_norm": 0.003972369711846113,
      "learning_rate": 1.995418681598371e-06,
      "loss": 0.0757,
      "step": 3540
    },
    {
      "epoch": 0.9035377958768135,
      "grad_norm": 0.0067659481428563595,
      "learning_rate": 1.9445151438024944e-06,
      "loss": 0.0001,
      "step": 3550
    },
    {
      "epoch": 0.9060829727666073,
      "grad_norm": 0.004922682885080576,
      "learning_rate": 1.8936116060066176e-06,
      "loss": 0.0001,
      "step": 3560
    },
    {
      "epoch": 0.9086281496564012,
      "grad_norm": 0.007238026708364487,
      "learning_rate": 1.8427080682107407e-06,
      "loss": 0.0001,
      "step": 3570
    },
    {
      "epoch": 0.911173326546195,
      "grad_norm": 0.006983587518334389,
      "learning_rate": 1.791804530414864e-06,
      "loss": 0.0002,
      "step": 3580
    },
    {
      "epoch": 0.9137185034359888,
      "grad_norm": 0.006601405330002308,
      "learning_rate": 1.740900992618987e-06,
      "loss": 0.0002,
      "step": 3590
    },
    {
      "epoch": 0.9162636803257826,
      "grad_norm": 0.004936858080327511,
      "learning_rate": 1.6899974548231104e-06,
      "loss": 0.0001,
      "step": 3600
    },
    {
      "epoch": 0.9188088572155765,
      "grad_norm": 0.0036070640198886395,
      "learning_rate": 1.6390939170272336e-06,
      "loss": 0.0001,
      "step": 3610
    },
    {
      "epoch": 0.9213540341053703,
      "grad_norm": 0.004050758201628923,
      "learning_rate": 1.5881903792313567e-06,
      "loss": 0.0001,
      "step": 3620
    },
    {
      "epoch": 0.9238992109951641,
      "grad_norm": 0.0020564987789839506,
      "learning_rate": 1.5372868414354799e-06,
      "loss": 0.0001,
      "step": 3630
    },
    {
      "epoch": 0.926444387884958,
      "grad_norm": 0.0035940813831984997,
      "learning_rate": 1.486383303639603e-06,
      "loss": 0.0001,
      "step": 3640
    },
    {
      "epoch": 0.9289895647747518,
      "grad_norm": 0.0026773863937705755,
      "learning_rate": 1.4354797658437264e-06,
      "loss": 0.0001,
      "step": 3650
    },
    {
      "epoch": 0.9315347416645456,
      "grad_norm": 0.003287737490609288,
      "learning_rate": 1.3845762280478495e-06,
      "loss": 0.0001,
      "step": 3660
    },
    {
      "epoch": 0.9340799185543395,
      "grad_norm": 0.0033714815508574247,
      "learning_rate": 1.3336726902519725e-06,
      "loss": 0.0892,
      "step": 3670
    },
    {
      "epoch": 0.9366250954441334,
      "grad_norm": 0.006824773736298084,
      "learning_rate": 1.2827691524560958e-06,
      "loss": 0.0001,
      "step": 3680
    },
    {
      "epoch": 0.9391702723339272,
      "grad_norm": 0.0031381985172629356,
      "learning_rate": 1.231865614660219e-06,
      "loss": 0.0001,
      "step": 3690
    },
    {
      "epoch": 0.9417154492237211,
      "grad_norm": 0.0029525754507631063,
      "learning_rate": 1.1809620768643421e-06,
      "loss": 0.0001,
      "step": 3700
    },
    {
      "epoch": 0.9442606261135149,
      "grad_norm": 0.00810339767485857,
      "learning_rate": 1.1300585390684655e-06,
      "loss": 0.0002,
      "step": 3710
    },
    {
      "epoch": 0.9468058030033087,
      "grad_norm": 0.0051963250152766705,
      "learning_rate": 1.0791550012725884e-06,
      "loss": 0.0001,
      "step": 3720
    },
    {
      "epoch": 0.9493509798931026,
      "grad_norm": 0.005426454823464155,
      "learning_rate": 1.0282514634767116e-06,
      "loss": 0.0001,
      "step": 3730
    },
    {
      "epoch": 0.9518961567828964,
      "grad_norm": 0.003340455936267972,
      "learning_rate": 9.77347925680835e-07,
      "loss": 0.0001,
      "step": 3740
    },
    {
      "epoch": 0.9544413336726902,
      "grad_norm": 0.003951636143028736,
      "learning_rate": 9.264443878849581e-07,
      "loss": 0.0001,
      "step": 3750
    },
    {
      "epoch": 0.9569865105624841,
      "grad_norm": 0.002056614961475134,
      "learning_rate": 8.755408500890812e-07,
      "loss": 0.0001,
      "step": 3760
    },
    {
      "epoch": 0.9595316874522779,
      "grad_norm": 0.0032017685007303953,
      "learning_rate": 8.246373122932044e-07,
      "loss": 0.0001,
      "step": 3770
    },
    {
      "epoch": 0.9620768643420717,
      "grad_norm": 0.0026975166983902454,
      "learning_rate": 7.737337744973277e-07,
      "loss": 0.0001,
      "step": 3780
    },
    {
      "epoch": 0.9646220412318656,
      "grad_norm": 0.003501919098198414,
      "learning_rate": 7.228302367014508e-07,
      "loss": 0.0887,
      "step": 3790
    },
    {
      "epoch": 0.9671672181216594,
      "grad_norm": 0.008241862989962101,
      "learning_rate": 6.71926698905574e-07,
      "loss": 0.0001,
      "step": 3800
    },
    {
      "epoch": 0.9697123950114533,
      "grad_norm": 0.007764929439872503,
      "learning_rate": 6.210231611096971e-07,
      "loss": 0.0001,
      "step": 3810
    },
    {
      "epoch": 0.9722575719012472,
      "grad_norm": 0.006334823556244373,
      "learning_rate": 5.701196233138204e-07,
      "loss": 0.0001,
      "step": 3820
    },
    {
      "epoch": 0.974802748791041,
      "grad_norm": 0.0037852548994123936,
      "learning_rate": 5.192160855179435e-07,
      "loss": 0.0001,
      "step": 3830
    },
    {
      "epoch": 0.9773479256808348,
      "grad_norm": 0.004409192129969597,
      "learning_rate": 4.6831254772206675e-07,
      "loss": 0.0001,
      "step": 3840
    },
    {
      "epoch": 0.9798931025706287,
      "grad_norm": 0.005172605160623789,
      "learning_rate": 4.1740900992618985e-07,
      "loss": 0.0001,
      "step": 3850
    },
    {
      "epoch": 0.9824382794604225,
      "grad_norm": 0.0068539720959961414,
      "learning_rate": 3.665054721303131e-07,
      "loss": 0.0001,
      "step": 3860
    },
    {
      "epoch": 0.9849834563502163,
      "grad_norm": 0.003507309826090932,
      "learning_rate": 3.1560193433443626e-07,
      "loss": 0.0001,
      "step": 3870
    },
    {
      "epoch": 0.9875286332400102,
      "grad_norm": 0.0023615779355168343,
      "learning_rate": 2.6469839653855947e-07,
      "loss": 0.0001,
      "step": 3880
    },
    {
      "epoch": 0.990073810129804,
      "grad_norm": 0.003375534899532795,
      "learning_rate": 2.1379485874268265e-07,
      "loss": 0.0001,
      "step": 3890
    },
    {
      "epoch": 0.9926189870195978,
      "grad_norm": 0.003960378933697939,
      "learning_rate": 1.6289132094680583e-07,
      "loss": 0.1046,
      "step": 3900
    },
    {
      "epoch": 0.9951641639093917,
      "grad_norm": 0.00308926566503942,
      "learning_rate": 1.11987783150929e-07,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 0.9977093407991855,
      "grad_norm": 0.004981337580829859,
      "learning_rate": 6.108424535505219e-08,
      "loss": 0.0001,
      "step": 3920
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9991091314031181,
      "eval_loss": 0.006104618776589632,
      "eval_runtime": 126.1499,
      "eval_samples_per_second": 53.389,
      "eval_steps_per_second": 6.675,
      "step": 3929
    }
  ],
  "logging_steps": 10,
  "max_steps": 3929,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1040796351240192.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
