{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea9d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4888738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr. No</th>\n",
       "      <th>Newspaper Name</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Content</th>\n",
       "      <th>Human Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>https://www.thehindu.com/news/national/sample-...</td>\n",
       "      <td>\"India Launches Chandrayaan-4 Successfully\"</td>\n",
       "      <td>India successfully launched Chandrayaan-4, aim...</td>\n",
       "      <td>India launched Chandrayaan-4 to study the moon...</td>\n",
       "      <td>Science and Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hindustan Times</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>https://www.hindustantimes.com/india/sample-ne...</td>\n",
       "      <td>\"PM Announces Digital India 2.0 on Independenc...</td>\n",
       "      <td>The Prime Minister unveiled the Digital India ...</td>\n",
       "      <td>PM launched Digital India 2.0, focusing on tec...</td>\n",
       "      <td>National News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Indian Express</td>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>https://www.indianexpress.com/news/sample-news-3</td>\n",
       "      <td>\"Economic Growth Rebounds in Q1 2021\"</td>\n",
       "      <td>India’s GDP showed a rebound in the first quar...</td>\n",
       "      <td>India's Q1 2021 GDP rebounded, indicating a re...</td>\n",
       "      <td>Business and Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Telegraph</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>https://www.telegraphindia.com/nation/sample-n...</td>\n",
       "      <td>\"Cyclone Yaas Causes Widespread Damage in East...</td>\n",
       "      <td>Cyclone Yaas wreaked havoc in Odisha and West ...</td>\n",
       "      <td>Cyclone Yaas caused severe damage in Eastern I...</td>\n",
       "      <td>Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deccan Chronicle</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>https://www.deccanchronicle.com/nation/sample-...</td>\n",
       "      <td>\"Hyderabad Emerges as India’s Vaccine Hub\"</td>\n",
       "      <td>Hyderabad became a central hub for COVID-19 va...</td>\n",
       "      <td>Hyderabad gained recognition as the COVID-19 v...</td>\n",
       "      <td>Health and Wellness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr. No    Newspaper Name Published Date  \\\n",
       "0       1         The Hindu     2023-12-01   \n",
       "1       2   Hindustan Times     2022-08-15   \n",
       "2       3    Indian Express     2021-04-10   \n",
       "3       4     The Telegraph     2023-05-18   \n",
       "4       5  Deccan Chronicle     2020-10-05   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.thehindu.com/news/national/sample-...   \n",
       "1  https://www.hindustantimes.com/india/sample-ne...   \n",
       "2   https://www.indianexpress.com/news/sample-news-3   \n",
       "3  https://www.telegraphindia.com/nation/sample-n...   \n",
       "4  https://www.deccanchronicle.com/nation/sample-...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0        \"India Launches Chandrayaan-4 Successfully\"   \n",
       "1  \"PM Announces Digital India 2.0 on Independenc...   \n",
       "2              \"Economic Growth Rebounds in Q1 2021\"   \n",
       "3  \"Cyclone Yaas Causes Widespread Damage in East...   \n",
       "4         \"Hyderabad Emerges as India’s Vaccine Hub\"   \n",
       "\n",
       "                                             Content  \\\n",
       "0  India successfully launched Chandrayaan-4, aim...   \n",
       "1  The Prime Minister unveiled the Digital India ...   \n",
       "2  India’s GDP showed a rebound in the first quar...   \n",
       "3  Cyclone Yaas wreaked havoc in Odisha and West ...   \n",
       "4  Hyderabad became a central hub for COVID-19 va...   \n",
       "\n",
       "                                       Human Summary                Category  \n",
       "0  India launched Chandrayaan-4 to study the moon...  Science and Technology  \n",
       "1  PM launched Digital India 2.0, focusing on tec...           National News  \n",
       "2  India's Q1 2021 GDP rebounded, indicating a re...    Business and Finance  \n",
       "3  Cyclone Yaas caused severe damage in Eastern I...             Environment  \n",
       "4  Hyderabad gained recognition as the COVID-19 v...     Health and Wellness  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Newsdataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d1e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Human Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India successfully launched Chandrayaan-4, aim...</td>\n",
       "      <td>India launched Chandrayaan-4 to study the moon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prime Minister unveiled the Digital India ...</td>\n",
       "      <td>PM launched Digital India 2.0, focusing on tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India’s GDP showed a rebound in the first quar...</td>\n",
       "      <td>India's Q1 2021 GDP rebounded, indicating a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyclone Yaas wreaked havoc in Odisha and West ...</td>\n",
       "      <td>Cyclone Yaas caused severe damage in Eastern I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyderabad became a central hub for COVID-19 va...</td>\n",
       "      <td>Hyderabad gained recognition as the COVID-19 v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  India successfully launched Chandrayaan-4, aim...   \n",
       "1  The Prime Minister unveiled the Digital India ...   \n",
       "2  India’s GDP showed a rebound in the first quar...   \n",
       "3  Cyclone Yaas wreaked havoc in Odisha and West ...   \n",
       "4  Hyderabad became a central hub for COVID-19 va...   \n",
       "\n",
       "                                       Human Summary  \n",
       "0  India launched Chandrayaan-4 to study the moon...  \n",
       "1  PM launched Digital India 2.0, focusing on tec...  \n",
       "2  India's Q1 2021 GDP rebounded, indicating a re...  \n",
       "3  Cyclone Yaas caused severe damage in Eastern I...  \n",
       "4  Hyderabad gained recognition as the COVID-19 v...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['Content','Human Summary']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f00efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cappr\\AppData\\Local\\Temp\\ipykernel_18152\\3830681562.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Human Summary'] = df1['Human Summary'].apply(lambda x: '<start> ' + x + ' <end>')\n"
     ]
    }
   ],
   "source": [
    "df1['Human Summary'] = df1['Human Summary'].apply(lambda x: '<start> ' + x + ' <end>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "181aca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data(texts, summaries, vocab_size=10000, max_text_len=100, max_summary_len=20):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(texts + summaries)\n",
    "    \n",
    "    text_sequences = tokenizer.texts_to_sequences(texts)\n",
    "    summary_sequences = tokenizer.texts_to_sequences(summaries)\n",
    "    \n",
    "    text_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        text_sequences, maxlen=max_text_len, padding='post')\n",
    "    summary_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        summary_sequences, maxlen=max_summary_len, padding='post')\n",
    "    \n",
    "    return text_padded, summary_padded, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fd4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Seq2Seq model\n",
    "def build_seq2seq_model(vocab_size, embedding_dim=100, lstm_units=128, max_text_len=100, max_summary_len=20):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_text_len,))\n",
    "    encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "    encoder_lstm, state_h, state_c = LSTM(lstm_units, return_state=True)(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_summary_len,))\n",
    "    decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Inference models\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(lstm_units,))\n",
    "    decoder_state_input_c = Input(shape=(lstm_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9acdc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def decode_sequence(input_seq, encoder_model, decoder_model, tokenizer, max_summary_len=20):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index['<start>']  # Assume <start> token exists\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = None\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == sampled_token_index:\n",
    "                sampled_word = word\n",
    "                break\n",
    "        \n",
    "        if sampled_word is None or sampled_word == '<end>' or len(decoded_sentence) > max_summary_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence.append(sampled_word)\n",
    "        \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return ' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d8db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_padded, summary_padded, tokenizer = prepare_data(df1['Content'], df1['Human Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41177b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 19)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Build and train model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model, encoder_model, decoder_model \u001b[38;5;241m=\u001b[39m build_seq2seq_model(\u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mword_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_padded\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_padded\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file39u1q169.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\cappr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 19)\n"
     ]
    }
   ],
   "source": [
    "# Build and train model\n",
    "model, encoder_model, decoder_model = build_seq2seq_model(len(tokenizer.word_index) + 1)\n",
    "model.fit([text_padded, summary_padded[:, :-1]], summary_padded[:, 1:],\n",
    "              batch_size=64, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57981441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72921b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
