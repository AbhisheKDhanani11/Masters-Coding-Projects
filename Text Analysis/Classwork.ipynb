{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0233b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac82586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was the best of times\n",
      "It was the worst of times\n",
      "It was the age of wisdom\n",
      "It was the age of foolishness\n",
      "What is the importance of age\n",
      "This is the best example.\n"
     ]
    }
   ],
   "source": [
    "file = open(\"text1.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed09b2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['It', 'was', 'the', 'best', 'of', 'times'], ['It', 'was', 'the', 'worst', 'of', 'times'], ['It', 'was', 'the', 'age', 'of', 'wisdom'], ['It', 'was', 'the', 'age', 'of', 'foolishness'], ['What', 'is', 'the', 'importance', 'of', 'age'], ['This', 'is', 'the', 'best', 'example.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b2d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e55308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.83333333 0.66666667 0.66666667 0.33333333 0.36514837]\n",
      " [0.83333333 0.         0.66666667 0.66666667 0.33333333 0.18257419]\n",
      " [0.66666667 0.66666667 0.         0.83333333 0.5        0.18257419]\n",
      " [0.66666667 0.66666667 0.83333333 0.         0.5        0.18257419]\n",
      " [0.33333333 0.33333333 0.5        0.5        0.         0.36514837]\n",
      " [0.36514837 0.18257419 0.18257419 0.18257419 0.36514837 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7877ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.19306449754902083, 1: 0.18095893645850156, 2: 0.1911855225552033, 3: 0.1911855225552033, 4: 0.14434636291527997, 5: 0.09925915796679063}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66ea0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.19306449754902083, ['It', 'was', 'the', 'best', 'of', 'times']), (0.1911855225552033, ['It', 'was', 'the', 'age', 'of', 'wisdom']), (0.1911855225552033, ['It', 'was', 'the', 'age', 'of', 'foolishness']), (0.18095893645850156, ['It', 'was', 'the', 'worst', 'of', 'times']), (0.14434636291527997, ['What', 'is', 'the', 'importance', 'of', 'age']), (0.09925915796679063, ['This', 'is', 'the', 'best', 'example.'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",ranked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "595c63e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 3\n",
      "Summarize Text: \n",
      " It was the best of times. It was the age of wisdom. It was the age of foolishness\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "    summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35406e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e576764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83070a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fec3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e3280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
